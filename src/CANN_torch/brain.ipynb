{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4810ebb-91b6-42c1-901a-1b802e9f9e95",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from trainer import *\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from models.CNN import StrainEnergyCANN_C, StrainEnergyCANN_polinomial3\n",
    "from sklearn.metrics import r2_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f10202b-6c63-46fb-86b6-456b34008f9d",
   "metadata": {},
   "source": [
    "# Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4f3773-8c4a-44b1-9a3e-c3ba15f652f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\User\\PycharmProjects\\data-driven-constitutive-modelling\\data\\brain_bade\\CANNsBRAINdata.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e270ed78-6be3-4749-8ba8-c6858be68005",
   "metadata": {},
   "outputs": [],
   "source": [
    "I1_tc = lambda lam: lam ** 2 + 2.0 / lam\n",
    "I2_tc = lambda lam: 2.0 * lam + 1 / lam ** 2\n",
    "I1_s = lambda gam: gam ** 2 + 3.0\n",
    "F_tc = lambda lam: ([lam, 0, 0], [0, lam **(-0.5), 0], [0, 0, lam**(-0.5)])\n",
    "F_s = lambda gam: ([1., gam, 0], [0, 1., 0], [0, 0, 1.])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c5a18d-91a7-401d-9c0e-f3d8de06ad7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_data = pd.read_excel(path, sheet_name=\"Sheet1\", header=[1, 2, 3])\n",
    "brain_CR_TC_data = all_data.filter(like=\"CR-comten\").copy()\n",
    "brain_CR_S_data  = all_data.filter(like=\"CR-shr\").copy().dropna(axis=1)\n",
    "\n",
    "brain_CR_TC_data.columns = brain_CR_TC_data.columns.droplevel(level=[0, 2])\n",
    "brain_CR_S_data.columns  = brain_CR_S_data.columns.droplevel(level=[0, 2])\n",
    "\n",
    "mechanical_variables = {\n",
    "    \"I1\": [I1_tc, I1_s],\n",
    "    \"I2\": [I2_tc, I1_s],\n",
    "    \"F\":  [F_tc, F_s],\n",
    "    # \"exp_type\": [(lambda x: 1), (lambda x: 0)] # 1 - torsion&compression, 0 - shear\n",
    "    # \"torsion_compression\": (lambda x: 1)\n",
    "}\n",
    "\n",
    "# calculate I1, I2, F from lambda (torsion&compression and shear)\n",
    "for variable in mechanical_variables.keys():\n",
    "    func_calc = mechanical_variables.get(variable)\n",
    "    brain_CR_TC_data[variable] = brain_CR_TC_data[\"lambda\"].apply(func_calc[0])\n",
    "    brain_CR_S_data[variable]  = brain_CR_S_data[\"gamma\"].apply(func_calc[1])\n",
    "    # I1 = pd.concat([brain_CR_TC_data[variable], brain_CR_S_data[variable]], ignore_index=True)\n",
    "brain_CR_S_data[\"lambda\"] = brain_CR_S_data.pop(\"gamma\")\n",
    "brain_CR_TC_data[\"exp_type\"] = [\"Compression\" if i < len(brain_CR_TC_data) / 2 else \"Tensile\"  for i in range(len(brain_CR_TC_data))]\n",
    "brain_CR_S_data[\"exp_type\"] = [\"Shear\"  for i in range(len(brain_CR_S_data))]\n",
    "data = pd.concat([brain_CR_TC_data, brain_CR_S_data], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1429b90-372d-4458-9cbe-dc4425cf051f",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = data\n",
    "combined_data.columns = ['lambda', 'P_experimental', 'I1', 'I2', 'F', 'experiment_type']"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7c517399-5617-4835-8b03-c58676ca6163",
   "metadata": {},
   "source": [
    "experiments = ['Compression', 'Tensile', 'Shear']\n",
    "combined_data = pd.concat([df.assign(Experiment=exp) for df, exp in zip(data_frames, experiments)]).reset_index(drop=True, inplace=False)\n",
    "combined_data.columns = ['lambda', 'P_experimental', 'I1', 'I2', 'F', 'experiment_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8e9598-d822-4789-a47a-75f454e52b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "g = sns.relplot(\n",
    "    data=combined_data,\n",
    "    x='lambda', y='P_experimental', col='experiment_type', kind='line', height=4, aspect=1.2, facet_kws={'sharey': False, 'sharex': False}\n",
    ")\n",
    "\n",
    "# Update axis labels\n",
    "g.set_axis_labels(\"Stretch\", \"Stress, kPa\")\n",
    "g.set_titles(\"{col_name}\")\n",
    "plt.savefig(\"brain\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131f838b-3048-4440-a17c-2a782d05772f",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dd5caa-1870-466f-b3f1-3eb9526dca84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split, Dataset, TensorDataset\n",
    "import copy \n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.data = dataframe\n",
    "        # self.features = [dataframe[0],dataframe[2], dataframe[3], dataframe[4], dataframe[5]]\n",
    "        # self.targets  = dataframe[1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        features = copy.deepcopy([*self.data.iloc[idx]][:6])\n",
    "        target = features.pop(1)\n",
    "\n",
    "        return features, target\n",
    "\n",
    "    def to_tensor(self):\n",
    "        for column in self.data.columns:\n",
    "            if column != \"experiment_type\":\n",
    "                self.data[column] = self.data[column].apply(\n",
    "                    lambda x: torch.tensor(x, dtype=torch.float32)).copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2885e307-29ba-4aaf-8367-24d5fa94676d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# start = 0\n",
    "# end = 49\n",
    "# train_dataset = CustomDataset(combined_data[start:end].copy())\n",
    "# test_dataset = CustomDataset(combined_data.copy())\n",
    "# f, t = train_dataset[0]\n",
    "# lam, i1, i2, F, exp_type = f\n",
    "# print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d21ccb-f9b6-4c5c-8a5b-bde8484b166c",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = [\"Shear\", \"Tensile\"]\n",
    "d = pd.concat([combined_data[combined_data[\"experiment_type\"] == experiment] for experiment in experiments]).reset_index(drop=True, inplace=False)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74875f48-209c-439c-9280-c5e80a41bde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_loaders(experiments=[\"Shear\", \"Tensile\", \"Comression\"]):\n",
    "    if type(experiments) == str:\n",
    "        experiments = [experiments]\n",
    "    print(experiments)\n",
    "    \n",
    "    df = pd.concat([combined_data[combined_data[\"experiment_type\"] == experiment] for experiment in experiments]).reset_index(drop=True, inplace=False)\n",
    "    train_dataset = CustomDataset(df.copy())\n",
    "    test_dataset = CustomDataset(combined_data.copy())\n",
    "    \n",
    "    train_dataset.to_tensor()\n",
    "    test_dataset.to_tensor()\n",
    "    \n",
    "    train_data_loader = DataLoader(\n",
    "                            train_dataset,\n",
    "                            shuffle=True,\n",
    "                            # num_workers=1,\n",
    "                            pin_memory=False\n",
    "    )\n",
    "    test_data_loader = DataLoader(\n",
    "                            test_dataset,\n",
    "                            shuffle=False,\n",
    "                            # num_workers=1,\n",
    "                            pin_memory=False\n",
    "    )\n",
    "\n",
    "    return train_data_loader, test_data_loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4849481-7add-46f9-a6d6-21e02d4815d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data_loader, test_data_loader = init_loaders(\"Compression\")\n",
    "train_data_loader.dataset.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f94f3fd-50d4-46b8-8655-0d18a3c4ec18",
   "metadata": {},
   "source": [
    "# Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9360732f-fa6b-473d-a2c9-862749c51c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments=[[\"Shear\", \"Tensile\", \"Comression\"],[\"Tensile\", \"Comression\"], [\"Tensile\", \"Shear\"], [\"Shear\", \"Comression\"], \"Shear\", \"Tensile\", \"Comression\"]\n",
    "for experiment in experiments:\n",
    "    print(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4e427b-6f31-4571-9577-e1278581b550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Переименуем столбцы для удобства\n",
    "# data.columns = ['strain', 'measured_force', 'I1', 'I2', 'F', 'experiment_type', 'predicted_force']\n",
    "\n",
    "# Удалим ненужные столбцы\n",
    "# data = data[['strain', 'measured_force', 'experiment_type', 'predicted_force']]\n",
    "def plot_results(data:pd.DataFrame, plot_name=\"\"):\n",
    "    # Преобразуем столбец с предсказанной силой в числовой формат\n",
    "    data['P_model_' + plot_name] = data['P_model_' + plot_name].apply(lambda x: float(str(x).strip('[]')))\n",
    "    \n",
    "    # Создадим графики для каждого типа эксперимента\n",
    "    experiment_types = data['experiment_type'].unique()\n",
    "    def plot_with_r2(data, experiment_types):\n",
    "        r2_scores = []\n",
    "        fig, axes = plt.subplots(1, len(experiment_types), figsize=(15, 6), sharey=False)\n",
    "        \n",
    "        for ax, experiment in zip(axes, experiment_types):\n",
    "            subset = data[data['experiment_type'] == experiment]\n",
    "            r2 = r2_score(subset['P_experimental'], subset['P_model_' + plot_name])\n",
    "            \n",
    "            sns.scatterplot(data=subset, x='lambda', y='P_experimental', label='P_experimental', ax=ax)\n",
    "            sns.lineplot(data=subset, x='lambda', y='P_model_' + plot_name, label='P_model', color='orange', ax=ax)\n",
    "            ax.set_title(f'Experiment Type: {experiment}\\nR² = {r2:.2f}')\n",
    "            ax.set_xlabel('Strain')\n",
    "            ax.set_ylabel('Force (kPa)')\n",
    "            r2_scores.append(r2)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(plot_name)\n",
    "        plt.show()\n",
    "        \n",
    "        return r2_scores\n",
    "    # Вызовем функцию для построения графиков с r2\n",
    "    plot_with_r2(data, experiment_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28327c59-a6ec-4082-ad51-8ce7c899398c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "experiments=[[\"Tensile\", \"Comression\"], [\"Tensile\", \"Shear\"], [\"Shear\", \"Comression\"], \"Shear\", \"Tensile\", \"Compression\"]\n",
    "# experiments = [\"Tensile\", \"Comression\", \"Shear\"]\n",
    "# models = [StrainEnergyCANN_C, StrainEnergyCANN_polinomial3]\n",
    "models = [StrainEnergyCANN_C]\n",
    "path = r\"C:\\Users\\User\\PycharmProjects\\data-driven-constitutive-modelling\\src\\CANN_torch\\pretrained_models\"\n",
    "best_model_path = r\"pretrained_models\\brain_StrainEnergyCANN_C\\20240523_1820_1400.pth\"\n",
    "for model in models:\n",
    "\n",
    "    # for idx, experiment in enumerate(experiments):\n",
    "        train_data_loader, test_data_loader = init_loaders()\n",
    "        name = \"brain_\" + str(model.__name__)\n",
    "        print(\"----------------------------------------------------------------------\")\n",
    "        print(experiment)\n",
    "        test_train = Trainer(\n",
    "            plot_valid=False,\n",
    "            epochs=3500,\n",
    "            experiment_name=name,\n",
    "            l2_reg_coeff=0.01,\n",
    "            learning_rate=0.001,\n",
    "            checkpoint=best_model_path,\n",
    "            model=model\n",
    "            # dtype = torch.float64\n",
    "        )\n",
    "        \n",
    "        trained_model = test_train.train(train_data_loader, None, weighting_data=True)\n",
    "    \n",
    "        trained_model.eval()\n",
    "        vpredictions = []\n",
    "        vtargets = []\n",
    "        for data in test_data_loader:\n",
    "            features, target = data\n",
    "            vpredictions.append(trained_model(features).detach().numpy())\n",
    "        print(trained_model.get_potential())\n",
    "        \n",
    "        combined_data[\"P_model_\" + name] = vpredictions\n",
    "        plot_results(combined_data, name)\n",
    "        combined_data.to_csv(os.path.join(os.path.join(path, str(name)), \"data.csv\"))\n",
    "        combined_data.pop(\"P_model_\" + name)\n",
    "# trained_model = StrainEnergyCANN_C()\n",
    "\n",
    "\n",
    "# print(\"R2:\", r2_score_own(vtargets, vpredictions))\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(vpredictions, label='P_pred', color='red')\n",
    "# plt.plot(vtargets, label='P_true', color='black')\n",
    "# plt.xlabel('lambda/gamma')\n",
    "# plt.ylabel('P')\n",
    "# plt.title('Predictions vs. Targets')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf389cac-f1aa-400a-800f-2e1d069ceccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = r\"C:\\Users\\drani\\dd\\data-driven-constitutive-modelling\\src\\CANN_torch\\pretrained_models\\PDMS_full\\20240522_1718_533.pth\"\n",
    "trained_model = StrainEnergyCANN_polinomial3()\n",
    "trained_model.load_state_dict(torch.load(best_model_path))\n",
    "trained_model.eval()\n",
    "vpredictions = []\n",
    "vtargets = []\n",
    "for data in test_data_loader:\n",
    "    features, target = data\n",
    "    vpredictions.append(trained_model(features).detach().numpy())\n",
    "print(trained_model.get_potential())\n",
    "combined_data[\"P_model\"] = vpredictions\n",
    "\n",
    "plot_results(combined_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efb8088-5b91-444e-8328-e61d88e0b82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = r\"C:\\Users\\drani\\dd\\data-driven-constitutive-modelling\\src\\CANN_torch\\pretrained_models\\PDMS_6term\\20240522_1851_466.pth\"\n",
    "trained_model = StrainEnergyCANN_C()\n",
    "trained_model.load_state_dict(torch.load(best_model_path))\n",
    "trained_model.eval()\n",
    "vpredictions = []\n",
    "vtargets = []\n",
    "for data in test_data_loader:\n",
    "    features, target = data\n",
    "    vpredictions.append(trained_model(features).detach().numpy())\n",
    "print(trained_model.get_potential())\n",
    "combined_data[\"P_model\"] = vpredictions\n",
    "\n",
    "plot_results(combined_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319160bd-67b8-4313-a38f-6439d3dd3c4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
