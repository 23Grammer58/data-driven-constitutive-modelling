{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e4810ebb-91b6-42c1-901a-1b802e9f9e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from trainer import *\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from models.CNN import StrainEnergyCANN_Ani\n",
    "from sklearn.metrics import r2_score\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f10202b-6c63-46fb-86b6-456b34008f9d",
   "metadata": {},
   "source": [
    "# Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dc4f3773-8c4a-44b1-9a3e-c3ba15f652f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = r\"..\\..\\data\\GoreTex\"\n",
    "# tensl_data_path = r\"..\\..\\data\\PDMS\\Shear_pdms.csv\"\n",
    "# shear_data_path = r\"..\\..\\data\\PDMS\\Tensile_pdms.csv\"\n",
    "# experiments_path = [compr_data_path, tensl_data_path, shear_data_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bec1fd21-f859-44d2-828b-0d6b29f5f506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['..\\\\..\\\\data\\\\GoreTex\\\\uniaxial\\\\GoreTex09mmUniX.csv',\n",
       " '..\\\\..\\\\data\\\\GoreTex\\\\uniaxial\\\\GoreTex09mmUniY.csv']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_list_of_paths_to_experiments_type(experiment=\"uniaxial\"):\n",
    "    experiment_type_path = os.path.join(path_to_data, experiment)\n",
    "    l = []\n",
    "    for file in os.listdir(experiment_type_path):\n",
    "        l.append(os.path.join(experiment_type_path, file))\n",
    "    return l\n",
    "\n",
    "def load_and_extract(file_path, experiment_type):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['experiment_type'] = experiment_type\n",
    "    return df[['lambda_clamps_X', 'lambda_clamps_Y', 'mean_stress_x_mpa', 'mean_stress_y_mpa', 'experiment_type']]\n",
    "\n",
    "get_list_of_paths_to_experiments_type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "03c5a18d-91a7-401d-9c0e-f3d8de06ad7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "experiment = \"uniaxial\"\n",
    "experiments_path = get_list_of_paths_to_experiments_type(experiment)\n",
    "data_frames = [load_and_extract(file, file[-11:-4]) for file in experiments_path]\n",
    "\n",
    "# print(data_frames)\n",
    "\n",
    "df = pd.concat(data_frames, ignore_index=True)\n",
    "thinned_data_frames = []\n",
    "num_points = 100\n",
    "\n",
    "sampled_df_list = []\n",
    "\n",
    "for df in data_frames:\n",
    "    indices = np.linspace(10, len(df) - 1, num_points, dtype=int)\n",
    "    # df[1] = df[1] / 10**6\n",
    "    sampled_df = pd.DataFrame(df.iloc[indices].copy())\n",
    "    # print(type(sampled_df))\n",
    "    sampled_df['lambdas'] = list(zip(sampled_df['lambda_clamps_X'], sampled_df['lambda_clamps_Y']))\n",
    "    sampled_df['stresses'] = list(zip(sampled_df['mean_stress_x_mpa'], sampled_df['mean_stress_y_mpa']))\n",
    "    sampled_df_list.append(sampled_df[:50])\n",
    "    # thinned_df = df.iloc[::len(df) // 20, :]  # Выбор каждого 45-го значения\n",
    "    # thinned_data_frames.append(thinned_df)\n",
    "data_frames = sampled_df_list\n",
    "data_frames = data_frames\n",
    "# sampled_df_list[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e270ed78-6be3-4749-8ba8-c6858be68005",
   "metadata": {},
   "outputs": [],
   "source": [
    "I1_bx = lambda lam1, lam2: lam1**2 + lam2**2 + 1 / (lam1 * lam2)**2\n",
    "I2_bx = lambda lam1, lam2: 1 / lam1**2 + 1 / lam2**2 + (lam1 * lam2)**2\n",
    "I4_bx = lambda lam1, lam2: lam1**2  + math.cos(math.pi / 4)**2 + lam2 * math.sin(torch.pi / 4)**2\n",
    "I5_bx = lambda lam1, lam2: lam1**2  + math.cos(math.pi / 4)**4 + lam2 * math.sin(torch.pi / 4)**4\n",
    "\n",
    "F_bx = lambda lam1, lam2: ([lam1, 0, 0], [0, lam2, 0], [0, 0, 1 / (lam1 * lam2)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "90912e42-1472-4e43-8fb7-08e3400d05ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_10820\\2117353720.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_frame[variable] = data_frame['lambdas'].apply(lambda lambdas: func_calc(lambdas[0], lambdas[0]))\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_10820\\2117353720.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_frame[variable] = data_frame['lambdas'].apply(lambda lambdas: func_calc(lambdas[0], lambdas[0]))\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_10820\\2117353720.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_frame[variable] = data_frame['lambdas'].apply(lambda lambdas: func_calc(lambdas[0], lambdas[0]))\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_10820\\2117353720.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_frame[variable] = data_frame['lambdas'].apply(lambda lambdas: func_calc(lambdas[0], lambdas[0]))\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_10820\\2117353720.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_frame[variable] = data_frame['lambdas'].apply(lambda lambdas: func_calc(lambdas[0], lambdas[0]))\n"
     ]
    }
   ],
   "source": [
    "mechanical_variables = {\n",
    "    \"I1\": I1_bx,\n",
    "    \"I2\": I2_bx,\n",
    "    \"I4\": I4_bx,\n",
    "    \"I5\": I5_bx,\n",
    "\n",
    "    \"F\": F_bx,\n",
    "    # \"exp_type\": [(lambda x: 1), (lambda x: 0)] # 1 - torsion&compression, 0 - shear\n",
    "    # \"torsion_compression\": (lambda x: 1)\n",
    "}\n",
    "\n",
    "# calculate I1, I2, F from lambda (torsion&compression and shear)\n",
    "for variable in mechanical_variables.keys():\n",
    "    func_calc = mechanical_variables.get(variable)\n",
    "\n",
    "    for data_frame in data_frames:\n",
    "        data_frame[variable] = data_frame['lambdas'].apply(lambda lambdas: func_calc(lambdas[0], lambdas[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "150c2c93-085f-431e-9f8f-927f9013caab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "experiments = ['Compression', 'Tensile', 'Shear']\n",
    "combined_data = pd.concat(data_frames).reset_index(drop=True, inplace=False)\n",
    "# combined_data.columns = ['lambda1', 'P_experimental', 'I1', 'I2', 'F', 'experiment_type']\n",
    "combined_data.pop(\"lambdas\")\n",
    "combined_data.pop(\"stresses\")\n",
    "experiment_type = combined_data.pop(\"experiment_type\")\n",
    "combined_data[\"experiment_type\"] = experiment_type\n",
    "combined_data\n",
    "combined_data.to_csv( \"Uniaxial.csv\")\n",
    "# combined_data = combined_data[\"lambda_clamps_X\", \"lambda_clamps_Y\",\t\"mean_stress_x_mpa\", \"mean_stress_y_mpa\", \"experiment_type\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ee885d53-1d28-4441-8574-ba63fd85fcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_combined_data = pd.DataFrame(columns=[\"lambdas, "
   ]
  },
  {
   "cell_type": "raw",
   "id": "b0b02a0f-03ce-4670-b6db-b0ae192fd6ea",
   "metadata": {},
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "g1 = sns.relplot(\n",
    "    data=combined_data,\n",
    "    x='lambda_clamps_Y', y='mean_stress_y_mpa', col='experiment_type', kind='line', height=4, aspect=1.2, facet_kws={'sharey': False, 'sharex': False}\n",
    ")\n",
    "\n",
    "# Update axis labels\n",
    "g1.set_axis_labels(\"Stretch1\", \"Stress1, MPa\")\n",
    "g1.set_titles(\"{col_name}\")\n",
    "plt.savefig(\"GoreTex_Y\")\n",
    "\n",
    "g2 = sns.relplot(\n",
    "    data=combined_data,\n",
    "    x='lambda_clamps_X', y='mean_stress_x_mpa', col='experiment_type', kind='line', height=4, aspect=1.2, facet_kws={'sharey': False, 'sharex': False}\n",
    ")\n",
    "\n",
    "# Update axis labels\n",
    "g2.set_axis_labels(\"Stretch\", \"Stress, MPa\")\n",
    "g2.set_titles(\"{col_name}\")\n",
    "plt.savefig(\"GoreTex_X\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f3dd5caa-1870-466f-b3f1-3eb9526dca84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split, Dataset, TensorDataset\n",
    "import copy \n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.data = dataframe\n",
    "        # self.features = [dataframe[0],dataframe[2], dataframe[3], dataframe[4], dataframe[5]]\n",
    "        # self.targets  = dataframe[1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        features = copy.deepcopy([*self.data.iloc[idx]])\n",
    "        target1 = features.pop(2)\n",
    "        target2 = features.pop(2)\n",
    "        target = torch.tensor([target1, target2])\n",
    "        return features, target\n",
    "\n",
    "    def to_tensor(self):\n",
    "        for column in self.data.columns:\n",
    "            if column != \"experiment_type\":\n",
    "                self.data[column] = self.data[column].apply(\n",
    "                    lambda x: torch.tensor(x, dtype=torch.float32)).copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2885e307-29ba-4aaf-8367-24d5fa94676d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0571428571428572, 1.0571428571428572, 3.0357936569581625, 3.038547748518468, 2.1461224489795923, 1.6318367346938776, ([1.0571428571428572, 0, 0], [0, 1.0571428571428572, 0], [0, 0, 0.8948137326515704]), '100_100']\n",
      "tensor([0.0023, 0.0262], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "start = 0\n",
    "end = -1\n",
    "train_dataset = CustomDataset(combined_data[start:end].copy())\n",
    "test_dataset = CustomDataset(combined_data.copy())\n",
    "f, t = train_dataset[1]\n",
    "# lam, i1, i2, F, exp_type = f\n",
    "print(f)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "37c362ac-5c3e-42ba-8e98-b9fb63423759",
   "metadata": {},
   "source": [
    "experiments = [\"Shear\", \"Tensile\"]\n",
    "d = pd.concat([combined_data[combined_data[\"experiment_type\"] == experiment] for experiment in experiments]).reset_index(drop=True, inplace=False)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "74875f48-209c-439c-9280-c5e80a41bde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_loaders(experiments:Optional[str]=[\"Shear\", \"Tensile\", \"Comression\"]):\n",
    "    if type(experiments) == str:\n",
    "        experiments = [experiments]\n",
    "    elif type(experiments) == list:\n",
    "        df = pd.concat([combined_data[combined_data[\"experiment_type\"] == experiment] for experiment in experiments]).reset_index(drop=True, inplace=False)\n",
    "    else:\n",
    "        df=combined_data\n",
    "    train_dataset = CustomDataset(df.copy())\n",
    "    test_dataset = CustomDataset(combined_data.copy())\n",
    "    \n",
    "    train_dataset.to_tensor()\n",
    "    test_dataset.to_tensor()\n",
    "    \n",
    "    train_data_loader = DataLoader(\n",
    "                            train_dataset,\n",
    "                            shuffle=True,\n",
    "                            # num_workers=1,\n",
    "                            pin_memory=False\n",
    "    )\n",
    "    test_data_loader = DataLoader(\n",
    "                            test_dataset,\n",
    "                            shuffle=False,\n",
    "                            # num_workers=1,\n",
    "                            pin_memory=False\n",
    "    )\n",
    "\n",
    "    return train_data_loader, test_data_loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d4849481-7add-46f9-a6d6-21e02d4815d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lambda_clamps_X</th>\n",
       "      <th>lambda_clamps_Y</th>\n",
       "      <th>mean_stress_x_mpa</th>\n",
       "      <th>mean_stress_y_mpa</th>\n",
       "      <th>I1</th>\n",
       "      <th>I2</th>\n",
       "      <th>I4</th>\n",
       "      <th>I5</th>\n",
       "      <th>F</th>\n",
       "      <th>experiment_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tensor(1.0571)</td>\n",
       "      <td>tensor(1.0571)</td>\n",
       "      <td>tensor(0.0023)</td>\n",
       "      <td>tensor(0.0262)</td>\n",
       "      <td>tensor(3.0358)</td>\n",
       "      <td>tensor(3.0385)</td>\n",
       "      <td>tensor(2.1461)</td>\n",
       "      <td>tensor(1.6318)</td>\n",
       "      <td>[[tensor(1.0571), tensor(0.), tensor(0.)], [te...</td>\n",
       "      <td>100_100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tensor(1.0571)</td>\n",
       "      <td>tensor(1.0571)</td>\n",
       "      <td>tensor(0.0023)</td>\n",
       "      <td>tensor(0.0262)</td>\n",
       "      <td>tensor(3.0358)</td>\n",
       "      <td>tensor(3.0385)</td>\n",
       "      <td>tensor(2.1461)</td>\n",
       "      <td>tensor(1.6318)</td>\n",
       "      <td>[[tensor(1.0571), tensor(0.), tensor(0.)], [te...</td>\n",
       "      <td>100_100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tensor(1.0629)</td>\n",
       "      <td>tensor(1.0629)</td>\n",
       "      <td>tensor(0.0027)</td>\n",
       "      <td>tensor(0.0330)</td>\n",
       "      <td>tensor(3.0429)</td>\n",
       "      <td>tensor(3.0466)</td>\n",
       "      <td>tensor(2.1611)</td>\n",
       "      <td>tensor(1.6454)</td>\n",
       "      <td>[[tensor(1.0629), tensor(0.), tensor(0.)], [te...</td>\n",
       "      <td>100_100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tensor(1.0686)</td>\n",
       "      <td>tensor(1.0686)</td>\n",
       "      <td>tensor(0.0032)</td>\n",
       "      <td>tensor(0.0397)</td>\n",
       "      <td>tensor(3.0507)</td>\n",
       "      <td>tensor(3.0554)</td>\n",
       "      <td>tensor(2.1761)</td>\n",
       "      <td>tensor(1.6590)</td>\n",
       "      <td>[[tensor(1.0686), tensor(0.), tensor(0.)], [te...</td>\n",
       "      <td>100_100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tensor(1.0743)</td>\n",
       "      <td>tensor(1.0743)</td>\n",
       "      <td>tensor(0.0038)</td>\n",
       "      <td>tensor(0.0480)</td>\n",
       "      <td>tensor(3.0590)</td>\n",
       "      <td>tensor(3.0649)</td>\n",
       "      <td>tensor(2.1912)</td>\n",
       "      <td>tensor(1.6727)</td>\n",
       "      <td>[[tensor(1.0743), tensor(0.), tensor(0.)], [te...</td>\n",
       "      <td>100_100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>tensor(1.2857)</td>\n",
       "      <td>tensor(1.0714)</td>\n",
       "      <td>tensor(0.3181)</td>\n",
       "      <td>tensor(0.8163)</td>\n",
       "      <td>tensor(3.6721)</td>\n",
       "      <td>tensor(3.9425)</td>\n",
       "      <td>tensor(2.7959)</td>\n",
       "      <td>tensor(2.2245)</td>\n",
       "      <td>[[tensor(1.2857), tensor(0.), tensor(0.)], [te...</td>\n",
       "      <td>100_033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>tensor(1.2800)</td>\n",
       "      <td>tensor(1.0700)</td>\n",
       "      <td>tensor(0.2889)</td>\n",
       "      <td>tensor(0.7761)</td>\n",
       "      <td>tensor(3.6493)</td>\n",
       "      <td>tensor(3.9051)</td>\n",
       "      <td>tensor(2.7784)</td>\n",
       "      <td>tensor(2.2084)</td>\n",
       "      <td>[[tensor(1.2800), tensor(0.), tensor(0.)], [te...</td>\n",
       "      <td>100_033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>tensor(1.2743)</td>\n",
       "      <td>tensor(1.0686)</td>\n",
       "      <td>tensor(0.2541)</td>\n",
       "      <td>tensor(0.7219)</td>\n",
       "      <td>tensor(3.6269)</td>\n",
       "      <td>tensor(3.8684)</td>\n",
       "      <td>tensor(2.7609)</td>\n",
       "      <td>tensor(2.1924)</td>\n",
       "      <td>[[tensor(1.2743), tensor(0.), tensor(0.)], [te...</td>\n",
       "      <td>100_033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>tensor(1.2686)</td>\n",
       "      <td>tensor(1.0671)</td>\n",
       "      <td>tensor(0.2276)</td>\n",
       "      <td>tensor(0.6891)</td>\n",
       "      <td>tensor(3.6047)</td>\n",
       "      <td>tensor(3.8326)</td>\n",
       "      <td>tensor(2.7436)</td>\n",
       "      <td>tensor(2.1764)</td>\n",
       "      <td>[[tensor(1.2686), tensor(0.), tensor(0.)], [te...</td>\n",
       "      <td>100_033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>tensor(1.2629)</td>\n",
       "      <td>tensor(1.0657)</td>\n",
       "      <td>tensor(0.2038)</td>\n",
       "      <td>tensor(0.6491)</td>\n",
       "      <td>tensor(3.5828)</td>\n",
       "      <td>tensor(3.7975)</td>\n",
       "      <td>tensor(2.7262)</td>\n",
       "      <td>tensor(2.1605)</td>\n",
       "      <td>[[tensor(1.2629), tensor(0.), tensor(0.)], [te...</td>\n",
       "      <td>100_033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>350 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    lambda_clamps_X lambda_clamps_Y mean_stress_x_mpa mean_stress_y_mpa  \\\n",
       "0    tensor(1.0571)  tensor(1.0571)    tensor(0.0023)    tensor(0.0262)   \n",
       "1    tensor(1.0571)  tensor(1.0571)    tensor(0.0023)    tensor(0.0262)   \n",
       "2    tensor(1.0629)  tensor(1.0629)    tensor(0.0027)    tensor(0.0330)   \n",
       "3    tensor(1.0686)  tensor(1.0686)    tensor(0.0032)    tensor(0.0397)   \n",
       "4    tensor(1.0743)  tensor(1.0743)    tensor(0.0038)    tensor(0.0480)   \n",
       "..              ...             ...               ...               ...   \n",
       "345  tensor(1.2857)  tensor(1.0714)    tensor(0.3181)    tensor(0.8163)   \n",
       "346  tensor(1.2800)  tensor(1.0700)    tensor(0.2889)    tensor(0.7761)   \n",
       "347  tensor(1.2743)  tensor(1.0686)    tensor(0.2541)    tensor(0.7219)   \n",
       "348  tensor(1.2686)  tensor(1.0671)    tensor(0.2276)    tensor(0.6891)   \n",
       "349  tensor(1.2629)  tensor(1.0657)    tensor(0.2038)    tensor(0.6491)   \n",
       "\n",
       "                 I1              I2              I4              I5  \\\n",
       "0    tensor(3.0358)  tensor(3.0385)  tensor(2.1461)  tensor(1.6318)   \n",
       "1    tensor(3.0358)  tensor(3.0385)  tensor(2.1461)  tensor(1.6318)   \n",
       "2    tensor(3.0429)  tensor(3.0466)  tensor(2.1611)  tensor(1.6454)   \n",
       "3    tensor(3.0507)  tensor(3.0554)  tensor(2.1761)  tensor(1.6590)   \n",
       "4    tensor(3.0590)  tensor(3.0649)  tensor(2.1912)  tensor(1.6727)   \n",
       "..              ...             ...             ...             ...   \n",
       "345  tensor(3.6721)  tensor(3.9425)  tensor(2.7959)  tensor(2.2245)   \n",
       "346  tensor(3.6493)  tensor(3.9051)  tensor(2.7784)  tensor(2.2084)   \n",
       "347  tensor(3.6269)  tensor(3.8684)  tensor(2.7609)  tensor(2.1924)   \n",
       "348  tensor(3.6047)  tensor(3.8326)  tensor(2.7436)  tensor(2.1764)   \n",
       "349  tensor(3.5828)  tensor(3.7975)  tensor(2.7262)  tensor(2.1605)   \n",
       "\n",
       "                                                     F experiment_type  \n",
       "0    [[tensor(1.0571), tensor(0.), tensor(0.)], [te...         100_100  \n",
       "1    [[tensor(1.0571), tensor(0.), tensor(0.)], [te...         100_100  \n",
       "2    [[tensor(1.0629), tensor(0.), tensor(0.)], [te...         100_100  \n",
       "3    [[tensor(1.0686), tensor(0.), tensor(0.)], [te...         100_100  \n",
       "4    [[tensor(1.0743), tensor(0.), tensor(0.)], [te...         100_100  \n",
       "..                                                 ...             ...  \n",
       "345  [[tensor(1.2857), tensor(0.), tensor(0.)], [te...         100_033  \n",
       "346  [[tensor(1.2800), tensor(0.), tensor(0.)], [te...         100_033  \n",
       "347  [[tensor(1.2743), tensor(0.), tensor(0.)], [te...         100_033  \n",
       "348  [[tensor(1.2686), tensor(0.), tensor(0.)], [te...         100_033  \n",
       "349  [[tensor(1.2629), tensor(0.), tensor(0.)], [te...         100_033  \n",
       "\n",
       "[350 rows x 10 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_loader, test_data_loader = init_loaders(None)\n",
    "train_data_loader.dataset.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f94f3fd-50d4-46b8-8655-0d18a3c4ec18",
   "metadata": {},
   "source": [
    "# Обучение модели"
   ]
  },
  {
   "cell_type": "raw",
   "id": "03819dd7-5371-43ff-b392-45fcfd9c32c6",
   "metadata": {},
   "source": [
    "experiments=[[\"Shear\", \"Tensile\", \"Comression\"],[\"Tensile\", \"Comression\"], [\"Tensile\", \"Shear\"], [\"Shear\", \"Comression\"], \"Shear\", \"Tensile\", \"Comression\"]\n",
    "for experiment in experiments:\n",
    "    print(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5d4e427b-6f31-4571-9577-e1278581b550",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results_by_experiment_type(data: pd.DataFrame, plot_name_prefix=\"plot\"):\n",
    "    \n",
    "    # Переименовываем столбцы для удобства\n",
    "    data.columns = ['index', 'lambda_x', 'lambda_y', 'stress_x', 'stress_y', 'I1', 'I2', 'I4', 'I5', 'F', 'experiment_type', 'P11', 'P22']\n",
    "\n",
    "    # Получим уникальные типы экспериментов\n",
    "    experiment_types = data['experiment_type'].unique()\n",
    "    \n",
    "    for experiment in experiment_types:\n",
    "        subset = data[data['experiment_type'] == experiment]\n",
    "        \n",
    "        # Создадим первый график (lambda_x, P11) и скаттер на нем stress_x для данного типа эксперимента\n",
    "        fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "        \n",
    "        sns.lineplot(data=subset, x='lambda_x', y='P11', ax=ax1, label='P11')\n",
    "        sns.scatterplot(data=subset, x='lambda_x', y='stress_x', ax=ax1, color='red', label='Stress_x')\n",
    "        \n",
    "        # Рассчитаем R² для P11\n",
    "        r2_p11 = r2_score(subset['stress_x'], subset['P11'])\n",
    "        \n",
    "        ax1.set_title(f'{experiment}: P11 and Stress_x\\nR² = {r2_p11:.2f}')\n",
    "        ax1.set_xlabel('Lambda_x')\n",
    "        ax1.set_ylabel('P11 / Stress_x (MPa)')\n",
    "        plt.legend()\n",
    "        plt.savefig(f\"{plot_name_prefix}_{experiment}_plot1.png\")\n",
    "        plt.show()\n",
    "        \n",
    "        # Создадим второй график (lambda_y, P22) и скаттер на нем stress_y для данного типа эксперимента\n",
    "        fig, ax2 = plt.subplots(figsize=(10, 6))\n",
    "        \n",
    "        sns.lineplot(data=subset, x='lambda_y', y='P22', ax=ax2, label='P22')\n",
    "        sns.scatterplot(data=subset, x='lambda_y', y='stress_y', ax=ax2, color='blue', label='Stress_y')\n",
    "        \n",
    "        # Рассчитаем R² для P22\n",
    "        r2_p22 = r2_score(subset['stress_y'], subset['P22'])\n",
    "        \n",
    "        ax2.set_title(f'{experiment}: P22 and Stress_y\\nR² = {r2_p22:.2f}')\n",
    "        ax2.set_xlabel('Lambda_y')\n",
    "        ax2.set_ylabel('P22 / Stress_y (MPa)')\n",
    "        plt.legend()\n",
    "        plt.savefig(f\"{plot_name_prefix}_{experiment}_plot2.png\")\n",
    "        plt.show()\n",
    "\n",
    "# Вызовем функцию plot_results_by_experiment_type с нашими данными\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "aab4e07f-ce2a-4177-a866-da6fb73385c8",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# experiments=[[\"Tensile\", \"Comression\"], [\"Tensile\", \"Shear\"], [\"Shear\", \"Comression\"], \"Shear\", \"Tensile\", \"Compression\"]\n",
    "# experiments = [\"Tensile\", \"Comression\", \"Shear\"]\n",
    "# models = [StrainEnergyCANN_C, StrainEnergyCANN_polinomial3]\n",
    "models = [StrainEnergyCANN_Ani]\n",
    "path = r\"C:\\Users\\User\\PycharmProjects\\data-driven-constitutive-modelling\\src\\CANN_torch\\pretrained_models\"\n",
    "for model in models:\n",
    "\n",
    "\n",
    "    # for idx, experiment in enumerate(experiments):\n",
    "        train_data_loader, test_data_loader = init_loaders(None)\n",
    "        name = \"GoreTex_\" + str(model.__name__)\n",
    "        print(\"----------------------------------------------------------------------\")\n",
    "        # print(experiment)\n",
    "        test_train = Trainer(\n",
    "            plot_valid=False,\n",
    "            epochs=20,\n",
    "            experiment_name=name,\n",
    "            l2_reg_coeff=None,\n",
    "            l1_reg_coeff=None,\n",
    "            learning_rate=0.0001,\n",
    "            checkpoint=None,\n",
    "            model=model,\n",
    "            \n",
    "            # dtype = torch.float64\n",
    "        )\n",
    "        \n",
    "        trained_model = test_train.train(train_data_loader, None, weighting_data=False)\n",
    "    \n",
    "        trained_model.eval()\n",
    "        vpredictions = []\n",
    "        vtargets = []\n",
    "        for data in test_data_loader:\n",
    "            features, target = data\n",
    "            # vpredictions.append(zip(trained_model(features).detach().numpy()))\n",
    "            vpredictions.append(trained_model(features).detach().numpy())\n",
    "        # print(trained_model.get_potential())\n",
    "        print(trained_model.potential_constants)\n",
    "        vpredictions = np.array(vpredictions)\n",
    "        print(vpredictions.transpose()[0])\n",
    "        combined_data[\"P11_model_\" + name] = vpredictions.transpose()[0]\n",
    "        combined_data[\"P22_model_\" + name] = vpredictions.transpose()[1]\n",
    "        combined_data.to_csv(os.path.join(os.path.join(path, str(name)), \"data.csv\"))\n",
    "        plot_results_by_experiment_type(combined_data)\n",
    "        combined_data.pop(\"P11_model_\" + name)\n",
    "        combined_data.pop(\"P22_model_\" + name)\n",
    "# trained_model = StrainEnergyCANN_C()\n",
    "\n",
    "# print(\"R2:\", r2_score_own(vtargets, vpredictions))\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(vpredictions, label='P_pred', color='red')\n",
    "# plt.plot(vtargets, label='P_true', color='black')\n",
    "# plt.xlabel('lambda/gamma')\n",
    "# plt.ylabel('P')\n",
    "# plt.title('Predictions vs. Targets')\n",
    "# plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aebf1d51-f04f-404a-9bc5-c6c4a9146623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single_inv_net1.w11.weight: tensor([[-0.]], dtype=torch.float64)\n",
      "single_inv_net1.w21.weight: tensor([[0.8063]], dtype=torch.float64)\n",
      "single_inv_net1.w31.weight: tensor([[-0.]], dtype=torch.float64)\n",
      "single_inv_net1.w41.weight: tensor([[0.0646]], dtype=torch.float64)\n",
      "single_inv_net2.w11.weight: tensor([[-0.]], dtype=torch.float64)\n",
      "single_inv_net2.w21.weight: tensor([[0.4887]], dtype=torch.float64)\n",
      "single_inv_net2.w31.weight: tensor([[-0.]], dtype=torch.float64)\n",
      "single_inv_net2.w41.weight: tensor([[1.0951]], dtype=torch.float64)\n",
      "single_inv_net4.w11.weight: tensor([[0.1322]], dtype=torch.float64)\n",
      "single_inv_net4.w21.weight: tensor([[0.6151]], dtype=torch.float64)\n",
      "single_inv_net4.w31.weight: tensor([[1.4809]], dtype=torch.float64)\n",
      "single_inv_net4.w41.weight: tensor([[0.4966]], dtype=torch.float64)\n",
      "single_inv_net5.w11.weight: tensor([[1.2356]], dtype=torch.float64)\n",
      "single_inv_net5.w21.weight: tensor([[0.9038]], dtype=torch.float64)\n",
      "single_inv_net5.w31.weight: tensor([[-0.]], dtype=torch.float64)\n",
      "single_inv_net5.w41.weight: tensor([[1.2236]], dtype=torch.float64)\n",
      "wx2.weight: tensor([[-0.0000, 0.0014, -0.0000, 0.0003, -0.0000, 0.0010, -0.0000, 0.0014, 0.0251,\n",
      "         0.0020, 0.0870, 0.0015, 0.0093, 0.0011, -0.0000, 0.0006]],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "import torch\n",
    "\n",
    "# Provided weights\n",
    "weights = [[-0.00000000e+00, -0.00000000e+00],\n",
    " [ 8.06281149e-01,  1.40696345e-03],\n",
    " [-0.00000000e+00, -0.00000000e+00],\n",
    " [ 6.46267161e-02,  2.84846843e-04],\n",
    " [-0.00000000e+00, -0.00000000e+00],\n",
    " [ 4.88660574e-01,  1.02614926e-03],\n",
    " [-0.00000000e+00, -0.00000000e+00],\n",
    " [ 1.09509790e+00,  1.44241273e-03],\n",
    " [ 1.32167622e-01,  2.50902846e-02],\n",
    " [ 6.15145266e-01,  1.99771114e-03],\n",
    " [ 1.48086607e+00,  8.69683549e-02],\n",
    " [ 4.96627361e-01,  1.48953160e-03],\n",
    " [ 1.23559475e+00,  9.31678526e-03],\n",
    " [ 9.03831899e-01,  1.09326339e-03],\n",
    " [-0.00000000e+00, -0.00000000e+00],\n",
    " [ 1.22360349e+00,  6.04832545e-04]]\n",
    "\n",
    "weights = np.array(weights).transpose().reshape(32)\n",
    "# Convert weights to tensors\n",
    "weight_tensors = [torch.tensor([[w]]) for w in weights]\n",
    "\n",
    "# Create OrderedDict\n",
    "model_weights = OrderedDict([\n",
    "    ('single_inv_net1.w11.weight', weight_tensors[0]),\n",
    "    ('single_inv_net1.w21.weight', weight_tensors[1]),\n",
    "    ('single_inv_net1.w31.weight', weight_tensors[2]),\n",
    "    ('single_inv_net1.w41.weight', weight_tensors[3]),\n",
    "    ('single_inv_net2.w11.weight', weight_tensors[4]),\n",
    "    ('single_inv_net2.w21.weight', weight_tensors[5]),\n",
    "    ('single_inv_net2.w31.weight', weight_tensors[6]),\n",
    "    ('single_inv_net2.w41.weight', weight_tensors[7]),\n",
    "    ('single_inv_net4.w11.weight', weight_tensors[8]),\n",
    "    ('single_inv_net4.w21.weight', weight_tensors[9]),\n",
    "    ('single_inv_net4.w31.weight', weight_tensors[10]),\n",
    "    ('single_inv_net4.w41.weight', weight_tensors[11]),\n",
    "    ('single_inv_net5.w11.weight', weight_tensors[12]),\n",
    "    ('single_inv_net5.w21.weight', weight_tensors[13]),\n",
    "    ('single_inv_net5.w31.weight', weight_tensors[14]),\n",
    "    ('single_inv_net5.w41.weight', weight_tensors[15]),\n",
    "    ('wx2.weight', torch.tensor([weight_tensors[16:]]))\n",
    "])\n",
    "\n",
    "# Display the model weights\n",
    "for key, value in model_weights.items():\n",
    "    print(f\"{key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4df72803-bb51-46d0-89a7-225dafcfe638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0000e+00, 8.0628e-01, -0.0000e+00, 6.4627e-02, -0.0000e+00, 4.8866e-01,\n",
      "         -0.0000e+00, 1.0951e+00, 1.3217e-01, 6.1515e-01, 1.4809e+00, 4.9663e-01,\n",
      "         1.2356e+00, 9.0383e-01, -0.0000e+00, 1.2236e+00],\n",
      "        [-0.0000e+00, 1.4070e-03, -0.0000e+00, 2.8485e-04, -0.0000e+00, 1.0261e-03,\n",
      "         -0.0000e+00, 1.4424e-03, 2.5090e-02, 1.9977e-03, 8.6968e-02, 1.4895e-03,\n",
      "         9.3168e-03, 1.0933e-03, -0.0000e+00, 6.0483e-04]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0.000000 * (I1 - 3) \\\\\\\\               + 0.001407 * (e^{  0.806281 * (I1 - 3)} - 1)\\\\\\\\               + 0.000000 * (I1 - 3) ^ 2 \\\\\\\\               + 0.000285 * (e^{  0.064627 * (I1 - 3) ^ 2} - 1)\\\\\\\\                               + 0.000000 * (I2 - 3) \\\\\\\\               + 0.001026 * (e^{  0.488661 * (I2 - 3))} - 1)\\\\\\\\               + 0.000000 * (I2 - 3) ^ 2 \\\\\\\\               + 0.001442 * (e^{  1.095098 * (I2 - 3) ^ 2)} - 1) \\\\\\\\                               + 0.003316 * (I4 - 3) \\\\\\\\                + 0.001998 * (e^{  0.615145 * (I4 - 3)} - 1)\\\\\\\\                + 0.128788 * (I4 - 3) ^ 2 \\\\\\\\                + 0.001490 * (e^{  0.496627 * (I4 - 3) ^ 2} - 1)\\\\\\\\                                + 0.011512 * (I5 - 3) \\\\\\\\                + 0.001093 * (e^{  0.903832 * (I5 - 3))} - 1)\\\\\\\\                + 0.000000 * (I5 - 3) ^ 2 \\\\\\\\                + 0.000605 * (e^{  1.223603 * (I5 - 3) ^ 2)} - 1)\\\\\\\\ '"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model =StrainEnergyCANN_Ani()\n",
    "# trained_model.load_state_dict(torch.load(r\"C:\\Users\\User\\PycharmProjects\\data-driven-constitutive-modelling\\src\\CANN_torch\\pretrained_models\\GoreTex_StrainEnergyCANN_Ani\\20240530_0108_206.pth\"))\n",
    "trained_model.load_state_dict(model_weights)\n",
    "trained_model.state_dict()\n",
    "trained_model.get_potential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0a20ed-6cd7-4cc3-a859-168f0f8e1129",
   "metadata": {},
   "source": [
    "$ 0.001407 * (e^{  0.806281 * (I1 - 3)} - 1)\\\\\\\\ + 0.000285 * (e^{  0.064627 * (I1 - 3) ^ 2} - 1)\\\\\\\\ + 0.001026 * (e^{  0.488661 * (I2 - 3))} - 1)\\\\\\\\ + 0.001442 * (e^{  1.095098 * (I2 - 3) ^ 2)} - 1) \\\\\\\\                               + 0.003316 * (I4 - 3) \\\\\\\\                + 0.001998 * (e^{  0.615145 * (I4 - 3)} - 1)\\\\\\\\                + 0.128788 * (I4 - 3) ^ 2 \\\\\\\\                + 0.001490 * (e^{  0.496627 * (I4 - 3) ^ 2} - 1)\\\\\\\\                                + 0.011512 * (I5 - 3) \\\\\\\\                + 0.001093 * (e^{  0.903832 * (I5 - 3))} - 1)\\\\\\\\ + 0.000605 * (e^{  1.223603 * (I5 - 3) ^ 2)} - 1)\\\\\\\\$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "02ef143e-032f-46d7-a44e-3ed463f5defa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0000e+00, 8.0628e-01, -0.0000e+00, 6.4627e-02, -0.0000e+00, 4.8866e-01,\n",
      "         -0.0000e+00, 1.0951e+00, 1.3217e-01, 6.1515e-01, 1.4809e+00, 4.9663e-01,\n",
      "         1.2356e+00, 9.0383e-01, -0.0000e+00, 1.2236e+00],\n",
      "        [-0.0000e+00, 1.4070e-03, -0.0000e+00, 2.8485e-04, -0.0000e+00, 1.0261e-03,\n",
      "         -0.0000e+00, 1.4424e-03, 2.5090e-02, 1.9977e-03, 8.6968e-02, 1.4895e-03,\n",
      "         9.3168e-03, 1.0933e-03, -0.0000e+00, 6.0483e-04]])\n",
      "[ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -4.64916229e-05 -4.64916229e-05\n",
      " -5.14388084e-05 -5.63263893e-05 -6.14523888e-05 -6.65783882e-05\n",
      " -7.18832016e-05 -7.73072243e-05 -8.28504562e-05 -8.85128975e-05\n",
      " -8.85128975e-05 -9.42945480e-05 -1.00314617e-04 -1.06394291e-04\n",
      " -1.12652779e-04 -1.19090080e-04 -1.25706196e-04 -1.32560730e-04\n",
      " -1.39534473e-04 -1.46687031e-04 -1.46687031e-04 -1.54078007e-04\n",
      " -1.61707401e-04 -1.69575214e-04 -1.77681446e-04 -1.85966492e-04\n",
      " -1.94489956e-04 -2.03371048e-04 -2.12490559e-04 -2.21967697e-04\n",
      " -2.21967697e-04 -2.31742859e-04 -2.41875648e-04 -2.52306461e-04\n",
      " -2.63154507e-04 -2.74360180e-04 -2.86042690e-04 -2.98142433e-04\n",
      " -3.10778618e-04 -3.24010849e-04 -3.24010849e-04 -3.37719917e-04\n",
      " -3.52025032e-04 -3.67045403e-04 -3.82781029e-04 -3.99351120e-04\n",
      " -3.82781029e-04 -3.67045403e-04 -3.52025032e-04 -3.37719917e-04\n",
      " -9.11951065e-05 -9.11951065e-05 -1.00314617e-04 -1.09493732e-04\n",
      " -1.18672848e-04 -1.28030777e-04 -1.37388706e-04 -1.46865845e-04\n",
      " -1.56402588e-04 -1.66058540e-04 -1.66058540e-04 -1.75833702e-04\n",
      " -1.85728073e-04 -1.95741653e-04 -2.05874443e-04 -2.16126442e-04\n",
      " -2.26497650e-04 -2.36988068e-04 -2.47657299e-04 -2.58505344e-04\n",
      " -2.58505344e-04 -2.69472599e-04 -2.80678272e-04 -2.91943550e-04\n",
      " -3.03506851e-04 -3.15129757e-04 -3.26991081e-04 -3.39090824e-04\n",
      " -3.51250172e-04 -3.63767147e-04 -3.63767147e-04 -3.76403332e-04\n",
      " -3.89277935e-04 -4.02331352e-04 -4.15623188e-04 -4.29153442e-04\n",
      " -4.42922115e-04 -4.56929207e-04 -4.71174717e-04 -4.85718250e-04\n",
      " -4.85718250e-04 -5.00500202e-04 -5.15520573e-04 -5.30898571e-04\n",
      " -5.46514988e-04 -5.62429428e-04 -5.46514988e-04 -5.30898571e-04\n",
      " -5.15520573e-04 -5.00500202e-04  9.73939896e-05  9.73939896e-05\n",
      "  1.08420849e-04  1.19924545e-04  1.31785870e-04  1.44183636e-04\n",
      "  1.57058239e-04  1.70409679e-04  1.84357166e-04  1.98900700e-04\n",
      "  1.98900700e-04  2.14040279e-04  2.29954720e-04  2.46524811e-04\n",
      "  2.63810158e-04  2.81929970e-04  3.00884247e-04  3.20792198e-04\n",
      "  3.41653824e-04  3.63647938e-04  3.63647938e-04  3.86774540e-04\n",
      "  4.11093235e-04  4.36782837e-04  4.64022160e-04  4.92751598e-04\n",
      "  5.23388386e-04  5.55872917e-04  5.90682030e-04  6.27875328e-04\n",
      "  6.27875328e-04  6.67691231e-04  7.10606575e-04  7.56978989e-04\n",
      "  8.07404518e-04  8.62121582e-04  9.21845436e-04  9.87529755e-04\n",
      "  1.05988979e-03  1.13999844e-03  1.13999844e-03  1.22904778e-03\n",
      "  1.32870674e-03  1.44088268e-03  1.56772137e-03  1.71196461e-03\n",
      "  1.56772137e-03  1.44088268e-03  1.32870674e-03  1.22904778e-03\n",
      " -4.64916229e-05 -4.64916229e-05 -5.14388084e-05 -5.63263893e-05\n",
      " -6.14523888e-05 -6.65783882e-05 -7.18832016e-05 -7.73072243e-05\n",
      " -8.28504562e-05 -8.85128975e-05 -8.85128975e-05 -9.42945480e-05\n",
      " -1.00314617e-04 -1.06394291e-04 -1.12652779e-04 -1.19090080e-04\n",
      " -1.25706196e-04 -1.32560730e-04 -1.39534473e-04 -1.46687031e-04\n",
      " -1.46687031e-04 -1.54078007e-04 -1.61707401e-04 -1.69575214e-04\n",
      " -1.77681446e-04 -1.85966492e-04 -1.94489956e-04 -2.03371048e-04\n",
      " -2.12490559e-04 -2.21967697e-04 -2.21967697e-04 -2.31742859e-04\n",
      " -2.41875648e-04 -2.52306461e-04 -2.63154507e-04 -2.74360180e-04\n",
      " -2.86042690e-04 -2.98142433e-04 -3.10778618e-04 -3.24010849e-04\n",
      " -3.24010849e-04 -3.37719917e-04 -3.52025032e-04 -3.67045403e-04\n",
      " -3.82781029e-04 -3.99351120e-04 -3.82781029e-04 -3.67045403e-04\n",
      " -3.52025032e-04 -3.37719917e-04 -1.35421753e-04 -1.35421753e-04\n",
      " -1.48594379e-04 -1.61767006e-04 -1.74820423e-04 -1.87873840e-04\n",
      " -2.00867653e-04 -2.13921070e-04 -2.26855278e-04 -2.39789486e-04\n",
      " -2.39789486e-04 -2.52783298e-04 -2.65777111e-04 -2.78711319e-04\n",
      " -2.91705132e-04 -3.04639339e-04 -3.17633152e-04 -3.30626965e-04\n",
      " -3.43620777e-04 -3.56674194e-04 -3.56674194e-04 -3.69727612e-04\n",
      " -3.82840633e-04 -3.95953655e-04 -4.09126282e-04 -4.22298908e-04\n",
      " -4.35531139e-04 -4.48822975e-04 -4.62114811e-04 -4.75466251e-04\n",
      " -4.75466251e-04 -4.88877296e-04 -5.02347946e-04 -5.15878201e-04\n",
      " -5.29468060e-04 -5.43057919e-04 -5.56766987e-04 -5.70535660e-04\n",
      " -5.84304333e-04 -5.98132610e-04 -5.98132610e-04 -6.12080097e-04\n",
      " -6.26146793e-04 -6.40213490e-04 -6.54339790e-04 -6.68585300e-04\n",
      " -6.54339790e-04 -6.40213490e-04 -6.26146793e-04 -6.12080097e-04\n",
      "  1.47402287e-04  1.47402287e-04  1.64330006e-04  1.81853771e-04\n",
      "  2.00152397e-04  2.19166279e-04  2.38955021e-04  2.59637833e-04\n",
      "  2.81214714e-04  3.03804874e-04  3.03804874e-04  3.27348709e-04\n",
      "  3.52084637e-04  3.78012657e-04  4.05073166e-04  4.33504581e-04\n",
      "  4.63426113e-04  4.94837761e-04  5.27918339e-04  5.62727451e-04\n",
      "  5.62727451e-04  5.99443913e-04  6.38246536e-04  6.79373741e-04\n",
      "  7.23004341e-04  7.69257545e-04  8.18550587e-04  8.71181488e-04\n",
      "  9.27567482e-04  9.88006592e-04  9.88006592e-04  1.05309486e-03\n",
      "  1.12342834e-03  1.19948387e-03  1.28233433e-03  1.37281418e-03\n",
      "  1.47199631e-03  1.58107281e-03  1.70183182e-03  1.83606148e-03\n",
      "  1.83606148e-03  1.98590755e-03  2.15399265e-03  2.34377384e-03\n",
      "  2.55918503e-03  2.80511379e-03  2.55918503e-03  2.34377384e-03\n",
      "  2.15399265e-03  1.98590755e-03]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (350) does not match length of index (100)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m vpredictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(vpredictions)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(vpredictions\u001b[38;5;241m.\u001b[39mtranspose()[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m vpredictions\u001b[38;5;241m.\u001b[39mtranspose()[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m---> 13\u001b[0m \u001b[43mcombined_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mP11_model_\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m vpredictions\u001b[38;5;241m.\u001b[39mtranspose()[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     14\u001b[0m combined_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP22_model_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name] \u001b[38;5;241m=\u001b[39m vpredictions\u001b[38;5;241m.\u001b[39mtranspose()[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# combined_data.to_csv(os.path.join(os.path.join(path, str(name)), \"data.csv\"))\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# plot_results_by_experiment_type(\"data.csv\")\u001b[39;00m\n",
      "File \u001b[1;32m~\\PycharmProjects\\data-driven-constitutive-modelling\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:4311\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4308\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[0;32m   4309\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4310\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[1;32m-> 4311\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\PycharmProjects\\data-driven-constitutive-modelling\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:4524\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4514\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   4515\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4516\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[0;32m   4517\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4522\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[0;32m   4523\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4524\u001b[0m     value, refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4526\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   4527\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m   4528\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   4529\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype)\n\u001b[0;32m   4530\u001b[0m     ):\n\u001b[0;32m   4531\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[0;32m   4532\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[1;32m~\\PycharmProjects\\data-driven-constitutive-modelling\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:5266\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   5263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m   5265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[1;32m-> 5266\u001b[0m     \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5267\u001b[0m arr \u001b[38;5;241m=\u001b[39m sanitize_array(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   5268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   5269\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(value, Index)\n\u001b[0;32m   5270\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5273\u001b[0m     \u001b[38;5;66;03m# TODO: Remove kludge in sanitize_array for string mode when enforcing\u001b[39;00m\n\u001b[0;32m   5274\u001b[0m     \u001b[38;5;66;03m# this deprecation\u001b[39;00m\n",
      "File \u001b[1;32m~\\PycharmProjects\\data-driven-constitutive-modelling\\venv\\Lib\\site-packages\\pandas\\core\\common.py:573\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    570\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[1;32m--> 573\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    574\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    575\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    576\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    577\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    578\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (350) does not match length of index (100)"
     ]
    }
   ],
   "source": [
    "# trained_model.load_state_dict(torch.load(r\"C:\\Users\\User\\PycharmProjects\\data-driven-constitutive-modelling\\src\\CANN_torch\\pretrained_models\\GoreTex_StrainEnergyCANN_Ani\\20240530_0108_206.pth\"))\n",
    "vpredictions = []\n",
    "vtargets = []\n",
    "for data in test_data_loader:\n",
    "    features, target = data\n",
    "    # vpredictions.append(zip(trained_model(features).detach().numpy()))\n",
    "    # print(trained_model(features))\n",
    "    vpredictions.append(trained_model(features).detach().numpy())\n",
    "# print(trained_model.get_potential())\n",
    "print(trained_model.potential_constants)\n",
    "vpredictions = np.array(vpredictions)\n",
    "print(vpredictions.transpose()[0] - vpredictions.transpose()[1])\n",
    "combined_data[\"P11_model_\" + name] = vpredictions.transpose()[0]\n",
    "combined_data[\"P22_model_\" + name] = vpredictions.transpose()[1]\n",
    "# combined_data.to_csv(os.path.join(os.path.join(path, str(name)), \"data.csv\"))\n",
    "# plot_results_by_experiment_type(\"data.csv\")\n",
    "combined_data.pop(\"P11_model_\" + name)\n",
    "combined_data.pop(\"P22_model_\" + name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "634cc886-add6-4ca2-9f78-92855ba25970",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 11 elements, new values have 13 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[64], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUser\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mPycharmProjects\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata-driven-constitutive-modelling\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124msrc\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mCANN_torch\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124muniaxial.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mplot_results_by_experiment_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[48], line 4\u001b[0m, in \u001b[0;36mplot_results_by_experiment_type\u001b[1;34m(data, plot_name_prefix)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_results_by_experiment_type\u001b[39m(data: pd\u001b[38;5;241m.\u001b[39mDataFrame, plot_name_prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplot\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m      2\u001b[0m     \n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# Переименовываем столбцы для удобства\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlambda_x\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlambda_y\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstress_x\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstress_y\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mI1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mI2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mI4\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mI5\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexperiment_type\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mP11\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mP22\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Получим уникальные типы экспериментов\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     experiment_types \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexperiment_type\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()\n",
      "File \u001b[1;32m~\\PycharmProjects\\data-driven-constitutive-modelling\\venv\\Lib\\site-packages\\pandas\\core\\generic.py:6313\u001b[0m, in \u001b[0;36mNDFrame.__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m   6311\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   6312\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\n\u001b[1;32m-> 6313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__setattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6314\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m   6315\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mproperties.pyx:69\u001b[0m, in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\PycharmProjects\\data-driven-constitutive-modelling\\venv\\Lib\\site-packages\\pandas\\core\\generic.py:814\u001b[0m, in \u001b[0;36mNDFrame._set_axis\u001b[1;34m(self, axis, labels)\u001b[0m\n\u001b[0;32m    809\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    810\u001b[0m \u001b[38;5;124;03mThis is called from the cython code when we set the `index` attribute\u001b[39;00m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;124;03mdirectly, e.g. `series.index = [1, 2, 3]`.\u001b[39;00m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    813\u001b[0m labels \u001b[38;5;241m=\u001b[39m ensure_index(labels)\n\u001b[1;32m--> 814\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    815\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[1;32m~\\PycharmProjects\\data-driven-constitutive-modelling\\venv\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:238\u001b[0m, in \u001b[0;36mBaseBlockManager.set_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_axis\u001b[39m(\u001b[38;5;28mself\u001b[39m, axis: AxisInt, new_labels: Index) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;66;03m# Caller is responsible for ensuring we have an Index object.\u001b[39;00m\n\u001b[1;32m--> 238\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_set_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis] \u001b[38;5;241m=\u001b[39m new_labels\n",
      "File \u001b[1;32m~\\PycharmProjects\\data-driven-constitutive-modelling\\venv\\Lib\\site-packages\\pandas\\core\\internals\\base.py:98\u001b[0m, in \u001b[0;36mDataManager._validate_set_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m new_len \u001b[38;5;241m!=\u001b[39m old_len:\n\u001b[1;32m---> 98\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength mismatch: Expected axis has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements, new \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    100\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    101\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length mismatch: Expected axis has 11 elements, new values have 13 elements"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\User\\PycharmProjects\\data-driven-constitutive-modelling\\src\\CANN_torch\\uniaxial.csv\")\n",
    "plot_results_by_experiment_type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ba3d9649-cb57-4cdf-b729-6f2052d0e769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StrainEnergyCANN_Ani.__name__ = \"test\"\n",
    "StrainEnergyCANN_Ani.__name__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba20f7e-2aec-4348-bbd0-2866fc1bd4cd",
   "metadata": {},
   "source": [
    "$psi =   0.000000 * (I1 - 3) \\\\               + 0.026245 * (e^{  0.000000 * (I1 - 3)} - 1)\\\\               - 0.025429 * ln(1 - 0.052720 * (I1 - 3)) \\\\               + 0.000000 * (I1 - 3) ^ 2 \\\\               + 0.085033 * (e^{  0.000000 * (I1 - 3) ^ 2} - 1)\\\\               - 0.077004 * ln(1 - 0.046803 * (I1 - 3) ^ 2) \\\\                               + 0.006244 * (I2 - 3) \\\\               + 0.046553 * (e^{  0.060594 * (I2 - 3))} - 1)\\\\               - 0.123550* ln(1 - 0.126146 *  (I2 - 3)) \\\\               + 0.000000 * (I2 - 3) ^ 2 \\\\               + 0.132380 * (e^{  0.051048 *(I2 - 3) ^ 2)} - 1)\\\\               - 0.018332* ln(1 - 0.074555 * (I2 - 3) ^ 2)\\\\$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db683014-ccb3-4392-a760-4f13416deae7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
