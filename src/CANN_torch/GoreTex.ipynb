{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4810ebb-91b6-42c1-901a-1b802e9f9e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from trainer import *\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from models.CNN import StrainEnergyCANN_Ani\n",
    "from sklearn.metrics import r2_score\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f10202b-6c63-46fb-86b6-456b34008f9d",
   "metadata": {},
   "source": [
    "# Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc4f3773-8c4a-44b1-9a3e-c3ba15f652f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = r\"..\\..\\data\\GoreTex\"\n",
    "# tensl_data_path = r\"..\\..\\data\\PDMS\\Shear_pdms.csv\"\n",
    "# shear_data_path = r\"..\\..\\data\\PDMS\\Tensile_pdms.csv\"\n",
    "# experiments_path = [compr_data_path, tensl_data_path, shear_data_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bec1fd21-f859-44d2-828b-0d6b29f5f506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['..\\\\..\\\\data\\\\GoreTex\\\\biaxial\\\\GoreTex080mm100_100.csv',\n",
       " '..\\\\..\\\\data\\\\GoreTex\\\\biaxial\\\\GoreTex089mm075_100.csv',\n",
       " '..\\\\..\\\\data\\\\GoreTex\\\\biaxial\\\\GoreTex090mm050_100.csv',\n",
       " '..\\\\..\\\\data\\\\GoreTex\\\\biaxial\\\\GoreTex090mm100_050.csv',\n",
       " '..\\\\..\\\\data\\\\GoreTex\\\\biaxial\\\\GoreTex090mm100_075.csv',\n",
       " '..\\\\..\\\\data\\\\GoreTex\\\\biaxial\\\\GoreTex096mm033_100.csv',\n",
       " '..\\\\..\\\\data\\\\GoreTex\\\\biaxial\\\\GoreTex096mm100_033.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_list_of_paths_to_experiments_type(experiment=\"biaxial\"):\n",
    "    experiment_type_path = os.path.join(path_to_data, experiment)\n",
    "    l = []\n",
    "    for file in os.listdir(experiment_type_path):\n",
    "        l.append(os.path.join(experiment_type_path, file))\n",
    "    return l\n",
    "\n",
    "def load_and_extract(file_path, experiment_type):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['experiment_type'] = experiment_type\n",
    "    return df[['lambda_clamps_X', 'lambda_clamps_Y', 'mean_stress_x_mpa', 'mean_stress_y_mpa', 'experiment_type']]\n",
    "\n",
    "get_list_of_paths_to_experiments_type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03c5a18d-91a7-401d-9c0e-f3d8de06ad7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lambda_clamps_X</th>\n",
       "      <th>lambda_clamps_Y</th>\n",
       "      <th>mean_stress_x_mpa</th>\n",
       "      <th>mean_stress_y_mpa</th>\n",
       "      <th>experiment_type</th>\n",
       "      <th>lambdas</th>\n",
       "      <th>stresses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.028571</td>\n",
       "      <td>1.057143</td>\n",
       "      <td>0.001607</td>\n",
       "      <td>0.027608</td>\n",
       "      <td>050_100</td>\n",
       "      <td>(1.0285714285714285, 1.0571428571428572)</td>\n",
       "      <td>(0.0016072188773338, 0.0276077712634154)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.031429</td>\n",
       "      <td>1.062857</td>\n",
       "      <td>0.002074</td>\n",
       "      <td>0.034651</td>\n",
       "      <td>050_100</td>\n",
       "      <td>(1.0314285714285714, 1.062857142857143)</td>\n",
       "      <td>(0.002073509042369, 0.0346511095457778)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.034286</td>\n",
       "      <td>1.068571</td>\n",
       "      <td>0.002591</td>\n",
       "      <td>0.043432</td>\n",
       "      <td>050_100</td>\n",
       "      <td>(1.0342857142857145, 1.0685714285714285)</td>\n",
       "      <td>(0.0025909158043805, 0.0434319165009779)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.037143</td>\n",
       "      <td>1.074286</td>\n",
       "      <td>0.003248</td>\n",
       "      <td>0.052552</td>\n",
       "      <td>050_100</td>\n",
       "      <td>(1.0371428571428571, 1.0742857142857145)</td>\n",
       "      <td>(0.0032484267440479, 0.0525524997351983)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.040000</td>\n",
       "      <td>1.080000</td>\n",
       "      <td>0.003959</td>\n",
       "      <td>0.062187</td>\n",
       "      <td>050_100</td>\n",
       "      <td>(1.04, 1.08)</td>\n",
       "      <td>(0.0039588978536403, 0.0621872863412342)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1.014286</td>\n",
       "      <td>1.028571</td>\n",
       "      <td>-0.000333</td>\n",
       "      <td>-0.002870</td>\n",
       "      <td>050_100</td>\n",
       "      <td>(1.0142857142857142, 1.0285714285714285)</td>\n",
       "      <td>(-0.0003331233728058, -0.0028698994360673)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1.011429</td>\n",
       "      <td>1.022857</td>\n",
       "      <td>-0.001027</td>\n",
       "      <td>-0.006587</td>\n",
       "      <td>050_100</td>\n",
       "      <td>(1.0114285714285711, 1.022857142857143)</td>\n",
       "      <td>(-0.001027261564481, -0.006587165520817)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1.008571</td>\n",
       "      <td>1.017143</td>\n",
       "      <td>-0.001743</td>\n",
       "      <td>-0.009434</td>\n",
       "      <td>050_100</td>\n",
       "      <td>(1.008571428571429, 1.0171428571428571)</td>\n",
       "      <td>(-0.0017429231925088, -0.0094336679450146)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1.005714</td>\n",
       "      <td>1.011429</td>\n",
       "      <td>-0.004714</td>\n",
       "      <td>-0.025783</td>\n",
       "      <td>050_100</td>\n",
       "      <td>(1.0057142857142858, 1.0114285714285711)</td>\n",
       "      <td>(-0.0047144159273535, -0.0257834317564309)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1.005714</td>\n",
       "      <td>1.011429</td>\n",
       "      <td>-0.004714</td>\n",
       "      <td>-0.025783</td>\n",
       "      <td>050_100</td>\n",
       "      <td>(1.0057142857142858, 1.0114285714285711)</td>\n",
       "      <td>(-0.0047144159273535, -0.0257834317564309)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    lambda_clamps_X  lambda_clamps_Y  mean_stress_x_mpa  mean_stress_y_mpa  \\\n",
       "10         1.028571         1.057143           0.001607           0.027608   \n",
       "11         1.031429         1.062857           0.002074           0.034651   \n",
       "12         1.034286         1.068571           0.002591           0.043432   \n",
       "13         1.037143         1.074286           0.003248           0.052552   \n",
       "14         1.040000         1.080000           0.003959           0.062187   \n",
       "..              ...              ...                ...                ...   \n",
       "95         1.014286         1.028571          -0.000333          -0.002870   \n",
       "96         1.011429         1.022857          -0.001027          -0.006587   \n",
       "97         1.008571         1.017143          -0.001743          -0.009434   \n",
       "98         1.005714         1.011429          -0.004714          -0.025783   \n",
       "99         1.005714         1.011429          -0.004714          -0.025783   \n",
       "\n",
       "   experiment_type                                   lambdas  \\\n",
       "10         050_100  (1.0285714285714285, 1.0571428571428572)   \n",
       "11         050_100   (1.0314285714285714, 1.062857142857143)   \n",
       "12         050_100  (1.0342857142857145, 1.0685714285714285)   \n",
       "13         050_100  (1.0371428571428571, 1.0742857142857145)   \n",
       "14         050_100                              (1.04, 1.08)   \n",
       "..             ...                                       ...   \n",
       "95         050_100  (1.0142857142857142, 1.0285714285714285)   \n",
       "96         050_100   (1.0114285714285711, 1.022857142857143)   \n",
       "97         050_100   (1.008571428571429, 1.0171428571428571)   \n",
       "98         050_100  (1.0057142857142858, 1.0114285714285711)   \n",
       "99         050_100  (1.0057142857142858, 1.0114285714285711)   \n",
       "\n",
       "                                      stresses  \n",
       "10    (0.0016072188773338, 0.0276077712634154)  \n",
       "11     (0.002073509042369, 0.0346511095457778)  \n",
       "12    (0.0025909158043805, 0.0434319165009779)  \n",
       "13    (0.0032484267440479, 0.0525524997351983)  \n",
       "14    (0.0039588978536403, 0.0621872863412342)  \n",
       "..                                         ...  \n",
       "95  (-0.0003331233728058, -0.0028698994360673)  \n",
       "96    (-0.001027261564481, -0.006587165520817)  \n",
       "97  (-0.0017429231925088, -0.0094336679450146)  \n",
       "98  (-0.0047144159273535, -0.0257834317564309)  \n",
       "99  (-0.0047144159273535, -0.0257834317564309)  \n",
       "\n",
       "[90 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment = \"biaxial\"\n",
    "experiments_path = get_list_of_paths_to_experiments_type(experiment)\n",
    "data_frames = [load_and_extract(file, file[-11:-4]) for file in experiments_path]\n",
    "\n",
    "# print(data_frames)\n",
    "\n",
    "df = pd.concat(data_frames, ignore_index=True)\n",
    "thinned_data_frames = []\n",
    "num_points = 90\n",
    "\n",
    "sampled_df_list = []\n",
    "\n",
    "for df in data_frames:\n",
    "    indices = np.linspace(10, len(df) - 1, num_points, dtype=int)\n",
    "    # df[1] = df[1] / 10**6\n",
    "    sampled_df = pd.DataFrame(df.iloc[indices].copy())\n",
    "    # print(type(sampled_df))\n",
    "    sampled_df['lambdas'] = list(zip(sampled_df['lambda_clamps_X'], sampled_df['lambda_clamps_Y']))\n",
    "    sampled_df['stresses'] = list(zip(sampled_df['mean_stress_x_mpa'], sampled_df['mean_stress_y_mpa']))\n",
    "    sampled_df_list.append(sampled_df)\n",
    "    # thinned_df = df.iloc[::len(df) // 20, :]  # Выбор каждого 45-го значения\n",
    "    # thinned_data_frames.append(thinned_df)\n",
    "data_frames = sampled_df_list\n",
    "data_frames[2]\n",
    "# sampled_df_list[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e270ed78-6be3-4749-8ba8-c6858be68005",
   "metadata": {},
   "outputs": [],
   "source": [
    "I1_bx = lambda lam1, lam2: lam1**2 + lam2**2 + 1 / (lam1 * lam2)**2\n",
    "I2_bx = lambda lam1, lam2: 1 / lam1**2 + 1 / lam2**2 + (lam1 * lam2)**2\n",
    "I4_bx = lambda lam1, lam2: lam1**2  + math.cos(math.pi / 4)**2 + lam2 * math.sin(torch.pi / 4)**2\n",
    "I5_bx = lambda lam1, lam2: lam1**2  + math.cos(math.pi / 4)**4 + lam2 * math.sin(torch.pi / 4)**4\n",
    "\n",
    "F_bx = lambda lam1, lam2: ([lam1, 0, 0], [0, lam2, 0], [0, 0, 1 / (lam1 * lam2)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90912e42-1472-4e43-8fb7-08e3400d05ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "mechanical_variables = {\n",
    "    \"I1\": I1_bx,\n",
    "    \"I2\": I2_bx,\n",
    "    \"I4\": I4_bx,\n",
    "    \"I5\": I5_bx,\n",
    "\n",
    "    \"F\": F_bx,\n",
    "    # \"exp_type\": [(lambda x: 1), (lambda x: 0)] # 1 - torsion&compression, 0 - shear\n",
    "    # \"torsion_compression\": (lambda x: 1)\n",
    "}\n",
    "\n",
    "# calculate I1, I2, F from lambda (torsion&compression and shear)\n",
    "for variable in mechanical_variables.keys():\n",
    "    func_calc = mechanical_variables.get(variable)\n",
    "\n",
    "    for data_frame in data_frames:\n",
    "        data_frame[variable] = data_frame['lambdas'].apply(lambda lambdas: func_calc(lambdas[0], lambdas[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "150c2c93-085f-431e-9f8f-927f9013caab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lambda_clamps_X</th>\n",
       "      <th>lambda_clamps_Y</th>\n",
       "      <th>mean_stress_x_mpa</th>\n",
       "      <th>mean_stress_y_mpa</th>\n",
       "      <th>I1</th>\n",
       "      <th>I2</th>\n",
       "      <th>I4</th>\n",
       "      <th>I5</th>\n",
       "      <th>F</th>\n",
       "      <th>experiment_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.057143</td>\n",
       "      <td>1.057143</td>\n",
       "      <td>0.002260</td>\n",
       "      <td>0.026224</td>\n",
       "      <td>3.035794</td>\n",
       "      <td>3.038548</td>\n",
       "      <td>2.146122</td>\n",
       "      <td>1.631837</td>\n",
       "      <td>([1.0571428571428572, 0, 0], [0, 1.05714285714...</td>\n",
       "      <td>100_100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.062857</td>\n",
       "      <td>1.062857</td>\n",
       "      <td>0.002675</td>\n",
       "      <td>0.033031</td>\n",
       "      <td>3.042941</td>\n",
       "      <td>3.046580</td>\n",
       "      <td>2.161094</td>\n",
       "      <td>1.645380</td>\n",
       "      <td>([1.062857142857143, 0, 0], [0, 1.062857142857...</td>\n",
       "      <td>100_100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.068571</td>\n",
       "      <td>1.068571</td>\n",
       "      <td>0.003215</td>\n",
       "      <td>0.039706</td>\n",
       "      <td>3.050673</td>\n",
       "      <td>3.055361</td>\n",
       "      <td>2.176131</td>\n",
       "      <td>1.658988</td>\n",
       "      <td>([1.0685714285714285, 0, 0], [0, 1.06857142857...</td>\n",
       "      <td>100_100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.074286</td>\n",
       "      <td>1.074286</td>\n",
       "      <td>0.003783</td>\n",
       "      <td>0.047987</td>\n",
       "      <td>3.058974</td>\n",
       "      <td>3.064891</td>\n",
       "      <td>2.191233</td>\n",
       "      <td>1.672661</td>\n",
       "      <td>([1.0742857142857145, 0, 0], [0, 1.07428571428...</td>\n",
       "      <td>100_100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.080000</td>\n",
       "      <td>1.080000</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>0.057191</td>\n",
       "      <td>3.067830</td>\n",
       "      <td>3.075167</td>\n",
       "      <td>2.206400</td>\n",
       "      <td>1.686400</td>\n",
       "      <td>([1.08, 0, 0], [0, 1.08, 0], [0, 0, 0.85733882...</td>\n",
       "      <td>100_100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>1.028571</td>\n",
       "      <td>1.007143</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>0.020486</td>\n",
       "      <td>3.009352</td>\n",
       "      <td>3.009710</td>\n",
       "      <td>2.072245</td>\n",
       "      <td>1.565102</td>\n",
       "      <td>([1.0285714285714285, 0, 0], [0, 1.02857142857...</td>\n",
       "      <td>100_033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>1.022857</td>\n",
       "      <td>1.005714</td>\n",
       "      <td>-0.000208</td>\n",
       "      <td>0.008024</td>\n",
       "      <td>3.006040</td>\n",
       "      <td>3.006225</td>\n",
       "      <td>2.057665</td>\n",
       "      <td>1.551951</td>\n",
       "      <td>([1.022857142857143, 0, 0], [0, 1.022857142857...</td>\n",
       "      <td>100_033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>1.017143</td>\n",
       "      <td>1.004286</td>\n",
       "      <td>-0.001441</td>\n",
       "      <td>-0.000880</td>\n",
       "      <td>3.003429</td>\n",
       "      <td>3.003507</td>\n",
       "      <td>2.043151</td>\n",
       "      <td>1.538865</td>\n",
       "      <td>([1.0171428571428571, 0, 0], [0, 1.01714285714...</td>\n",
       "      <td>100_033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>1.011429</td>\n",
       "      <td>1.002857</td>\n",
       "      <td>-0.005595</td>\n",
       "      <td>-0.013425</td>\n",
       "      <td>3.001538</td>\n",
       "      <td>3.001562</td>\n",
       "      <td>2.028702</td>\n",
       "      <td>1.525845</td>\n",
       "      <td>([1.0114285714285711, 0, 0], [0, 1.01142857142...</td>\n",
       "      <td>100_033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>1.011429</td>\n",
       "      <td>1.002857</td>\n",
       "      <td>-0.005595</td>\n",
       "      <td>-0.013425</td>\n",
       "      <td>3.001538</td>\n",
       "      <td>3.001562</td>\n",
       "      <td>2.028702</td>\n",
       "      <td>1.525845</td>\n",
       "      <td>([1.0114285714285711, 0, 0], [0, 1.01142857142...</td>\n",
       "      <td>100_033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>630 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     lambda_clamps_X  lambda_clamps_Y  mean_stress_x_mpa  mean_stress_y_mpa  \\\n",
       "0           1.057143         1.057143           0.002260           0.026224   \n",
       "1           1.062857         1.062857           0.002675           0.033031   \n",
       "2           1.068571         1.068571           0.003215           0.039706   \n",
       "3           1.074286         1.074286           0.003783           0.047987   \n",
       "4           1.080000         1.080000           0.004571           0.057191   \n",
       "..               ...              ...                ...                ...   \n",
       "625         1.028571         1.007143           0.000828           0.020486   \n",
       "626         1.022857         1.005714          -0.000208           0.008024   \n",
       "627         1.017143         1.004286          -0.001441          -0.000880   \n",
       "628         1.011429         1.002857          -0.005595          -0.013425   \n",
       "629         1.011429         1.002857          -0.005595          -0.013425   \n",
       "\n",
       "           I1        I2        I4        I5  \\\n",
       "0    3.035794  3.038548  2.146122  1.631837   \n",
       "1    3.042941  3.046580  2.161094  1.645380   \n",
       "2    3.050673  3.055361  2.176131  1.658988   \n",
       "3    3.058974  3.064891  2.191233  1.672661   \n",
       "4    3.067830  3.075167  2.206400  1.686400   \n",
       "..        ...       ...       ...       ...   \n",
       "625  3.009352  3.009710  2.072245  1.565102   \n",
       "626  3.006040  3.006225  2.057665  1.551951   \n",
       "627  3.003429  3.003507  2.043151  1.538865   \n",
       "628  3.001538  3.001562  2.028702  1.525845   \n",
       "629  3.001538  3.001562  2.028702  1.525845   \n",
       "\n",
       "                                                     F experiment_type  \n",
       "0    ([1.0571428571428572, 0, 0], [0, 1.05714285714...         100_100  \n",
       "1    ([1.062857142857143, 0, 0], [0, 1.062857142857...         100_100  \n",
       "2    ([1.0685714285714285, 0, 0], [0, 1.06857142857...         100_100  \n",
       "3    ([1.0742857142857145, 0, 0], [0, 1.07428571428...         100_100  \n",
       "4    ([1.08, 0, 0], [0, 1.08, 0], [0, 0, 0.85733882...         100_100  \n",
       "..                                                 ...             ...  \n",
       "625  ([1.0285714285714285, 0, 0], [0, 1.02857142857...         100_033  \n",
       "626  ([1.022857142857143, 0, 0], [0, 1.022857142857...         100_033  \n",
       "627  ([1.0171428571428571, 0, 0], [0, 1.01714285714...         100_033  \n",
       "628  ([1.0114285714285711, 0, 0], [0, 1.01142857142...         100_033  \n",
       "629  ([1.0114285714285711, 0, 0], [0, 1.01142857142...         100_033  \n",
       "\n",
       "[630 rows x 10 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiments = ['Compression', 'Tensile', 'Shear']\n",
    "combined_data = pd.concat(data_frames).reset_index(drop=True, inplace=False)\n",
    "# combined_data.columns = ['lambda1', 'P_experimental', 'I1', 'I2', 'F', 'experiment_type']\n",
    "combined_data.pop(\"lambdas\")\n",
    "combined_data.pop(\"stresses\")\n",
    "experiment_type = combined_data.pop(\"experiment_type\")\n",
    "combined_data[\"experiment_type\"] = experiment_type\n",
    "combined_data\n",
    "\n",
    "# combined_data = combined_data[\"lambda_clamps_X\", \"lambda_clamps_Y\",\t\"mean_stress_x_mpa\", \"mean_stress_y_mpa\", \"experiment_type\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee885d53-1d28-4441-8574-ba63fd85fcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_combined_data = pd.DataFrame(columns=[\"lambdas, "
   ]
  },
  {
   "cell_type": "raw",
   "id": "b0b02a0f-03ce-4670-b6db-b0ae192fd6ea",
   "metadata": {},
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "g1 = sns.relplot(\n",
    "    data=combined_data,\n",
    "    x='lambda_clamps_Y', y='mean_stress_y_mpa', col='experiment_type', kind='line', height=4, aspect=1.2, facet_kws={'sharey': False, 'sharex': False}\n",
    ")\n",
    "\n",
    "# Update axis labels\n",
    "g1.set_axis_labels(\"Stretch1\", \"Stress1, MPa\")\n",
    "g1.set_titles(\"{col_name}\")\n",
    "plt.savefig(\"GoreTex_Y\")\n",
    "\n",
    "g2 = sns.relplot(\n",
    "    data=combined_data,\n",
    "    x='lambda_clamps_X', y='mean_stress_x_mpa', col='experiment_type', kind='line', height=4, aspect=1.2, facet_kws={'sharey': False, 'sharex': False}\n",
    ")\n",
    "\n",
    "# Update axis labels\n",
    "g2.set_axis_labels(\"Stretch\", \"Stress, MPa\")\n",
    "g2.set_titles(\"{col_name}\")\n",
    "plt.savefig(\"GoreTex_X\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3dd5caa-1870-466f-b3f1-3eb9526dca84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split, Dataset, TensorDataset\n",
    "import copy \n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.data = dataframe\n",
    "        # self.features = [dataframe[0],dataframe[2], dataframe[3], dataframe[4], dataframe[5]]\n",
    "        # self.targets  = dataframe[1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        features = copy.deepcopy([*self.data.iloc[idx]])\n",
    "        target1 = features.pop(2)\n",
    "        target2 = features.pop(2)\n",
    "        target = torch.tensor([target1, target2])\n",
    "        return features, target\n",
    "\n",
    "    def to_tensor(self):\n",
    "        for column in self.data.columns:\n",
    "            if column != \"experiment_type\":\n",
    "                self.data[column] = self.data[column].apply(\n",
    "                    lambda x: torch.tensor(x, dtype=torch.float32)).copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2885e307-29ba-4aaf-8367-24d5fa94676d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.062857142857143, 1.062857142857143, 3.042941421104298, 3.0465795923987544, 2.161093877551021, 1.6453795918367349, ([1.062857142857143, 0, 0], [0, 1.062857142857143, 0], [0, 0, 0.8852179442710139]), '100_100']\n",
      "tensor([0.0027, 0.0330], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "start = 0\n",
    "end = -1\n",
    "train_dataset = CustomDataset(combined_data[start:end].copy())\n",
    "test_dataset = CustomDataset(combined_data.copy())\n",
    "f, t = train_dataset[1]\n",
    "# lam, i1, i2, F, exp_type = f\n",
    "print(f)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "37c362ac-5c3e-42ba-8e98-b9fb63423759",
   "metadata": {},
   "source": [
    "experiments = [\"Shear\", \"Tensile\"]\n",
    "d = pd.concat([combined_data[combined_data[\"experiment_type\"] == experiment] for experiment in experiments]).reset_index(drop=True, inplace=False)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74875f48-209c-439c-9280-c5e80a41bde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_loaders(experiments:Optional[str]=[\"Shear\", \"Tensile\", \"Comression\"]):\n",
    "    if type(experiments) == str:\n",
    "        experiments = [experiments]\n",
    "    elif type(experiments) == list:\n",
    "        df = pd.concat([combined_data[combined_data[\"experiment_type\"] == experiment] for experiment in experiments]).reset_index(drop=True, inplace=False)\n",
    "    else:\n",
    "        df=combined_data\n",
    "    train_dataset = CustomDataset(df.copy())\n",
    "    test_dataset = CustomDataset(combined_data.copy())\n",
    "    \n",
    "    train_dataset.to_tensor()\n",
    "    test_dataset.to_tensor()\n",
    "    \n",
    "    train_data_loader = DataLoader(\n",
    "                            train_dataset,\n",
    "                            shuffle=True,\n",
    "                            # num_workers=1,\n",
    "                            pin_memory=False\n",
    "    )\n",
    "    test_data_loader = DataLoader(\n",
    "                            test_dataset,\n",
    "                            shuffle=False,\n",
    "                            # num_workers=1,\n",
    "                            pin_memory=False\n",
    "    )\n",
    "\n",
    "    return train_data_loader, test_data_loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4849481-7add-46f9-a6d6-21e02d4815d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lambda_clamps_X</th>\n",
       "      <th>lambda_clamps_Y</th>\n",
       "      <th>mean_stress_x_mpa</th>\n",
       "      <th>mean_stress_y_mpa</th>\n",
       "      <th>I1</th>\n",
       "      <th>I2</th>\n",
       "      <th>I4</th>\n",
       "      <th>I5</th>\n",
       "      <th>F</th>\n",
       "      <th>experiment_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tensor(1.0571)</td>\n",
       "      <td>tensor(1.0571)</td>\n",
       "      <td>tensor(0.0023)</td>\n",
       "      <td>tensor(0.0262)</td>\n",
       "      <td>tensor(3.0358)</td>\n",
       "      <td>tensor(3.0385)</td>\n",
       "      <td>tensor(2.1461)</td>\n",
       "      <td>tensor(1.6318)</td>\n",
       "      <td>[[tensor(1.0571), tensor(0.), tensor(0.)], [te...</td>\n",
       "      <td>100_100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tensor(1.0629)</td>\n",
       "      <td>tensor(1.0629)</td>\n",
       "      <td>tensor(0.0027)</td>\n",
       "      <td>tensor(0.0330)</td>\n",
       "      <td>tensor(3.0429)</td>\n",
       "      <td>tensor(3.0466)</td>\n",
       "      <td>tensor(2.1611)</td>\n",
       "      <td>tensor(1.6454)</td>\n",
       "      <td>[[tensor(1.0629), tensor(0.), tensor(0.)], [te...</td>\n",
       "      <td>100_100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tensor(1.0686)</td>\n",
       "      <td>tensor(1.0686)</td>\n",
       "      <td>tensor(0.0032)</td>\n",
       "      <td>tensor(0.0397)</td>\n",
       "      <td>tensor(3.0507)</td>\n",
       "      <td>tensor(3.0554)</td>\n",
       "      <td>tensor(2.1761)</td>\n",
       "      <td>tensor(1.6590)</td>\n",
       "      <td>[[tensor(1.0686), tensor(0.), tensor(0.)], [te...</td>\n",
       "      <td>100_100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tensor(1.0743)</td>\n",
       "      <td>tensor(1.0743)</td>\n",
       "      <td>tensor(0.0038)</td>\n",
       "      <td>tensor(0.0480)</td>\n",
       "      <td>tensor(3.0590)</td>\n",
       "      <td>tensor(3.0649)</td>\n",
       "      <td>tensor(2.1912)</td>\n",
       "      <td>tensor(1.6727)</td>\n",
       "      <td>[[tensor(1.0743), tensor(0.), tensor(0.)], [te...</td>\n",
       "      <td>100_100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tensor(1.0800)</td>\n",
       "      <td>tensor(1.0800)</td>\n",
       "      <td>tensor(0.0046)</td>\n",
       "      <td>tensor(0.0572)</td>\n",
       "      <td>tensor(3.0678)</td>\n",
       "      <td>tensor(3.0752)</td>\n",
       "      <td>tensor(2.2064)</td>\n",
       "      <td>tensor(1.6864)</td>\n",
       "      <td>[[tensor(1.0800), tensor(0.), tensor(0.)], [te...</td>\n",
       "      <td>100_100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>tensor(1.0286)</td>\n",
       "      <td>tensor(1.0071)</td>\n",
       "      <td>tensor(0.0008)</td>\n",
       "      <td>tensor(0.0205)</td>\n",
       "      <td>tensor(3.0094)</td>\n",
       "      <td>tensor(3.0097)</td>\n",
       "      <td>tensor(2.0722)</td>\n",
       "      <td>tensor(1.5651)</td>\n",
       "      <td>[[tensor(1.0286), tensor(0.), tensor(0.)], [te...</td>\n",
       "      <td>100_033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>tensor(1.0229)</td>\n",
       "      <td>tensor(1.0057)</td>\n",
       "      <td>tensor(-0.0002)</td>\n",
       "      <td>tensor(0.0080)</td>\n",
       "      <td>tensor(3.0060)</td>\n",
       "      <td>tensor(3.0062)</td>\n",
       "      <td>tensor(2.0577)</td>\n",
       "      <td>tensor(1.5520)</td>\n",
       "      <td>[[tensor(1.0229), tensor(0.), tensor(0.)], [te...</td>\n",
       "      <td>100_033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>tensor(1.0171)</td>\n",
       "      <td>tensor(1.0043)</td>\n",
       "      <td>tensor(-0.0014)</td>\n",
       "      <td>tensor(-0.0009)</td>\n",
       "      <td>tensor(3.0034)</td>\n",
       "      <td>tensor(3.0035)</td>\n",
       "      <td>tensor(2.0432)</td>\n",
       "      <td>tensor(1.5389)</td>\n",
       "      <td>[[tensor(1.0171), tensor(0.), tensor(0.)], [te...</td>\n",
       "      <td>100_033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>tensor(1.0114)</td>\n",
       "      <td>tensor(1.0029)</td>\n",
       "      <td>tensor(-0.0056)</td>\n",
       "      <td>tensor(-0.0134)</td>\n",
       "      <td>tensor(3.0015)</td>\n",
       "      <td>tensor(3.0016)</td>\n",
       "      <td>tensor(2.0287)</td>\n",
       "      <td>tensor(1.5258)</td>\n",
       "      <td>[[tensor(1.0114), tensor(0.), tensor(0.)], [te...</td>\n",
       "      <td>100_033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>tensor(1.0114)</td>\n",
       "      <td>tensor(1.0029)</td>\n",
       "      <td>tensor(-0.0056)</td>\n",
       "      <td>tensor(-0.0134)</td>\n",
       "      <td>tensor(3.0015)</td>\n",
       "      <td>tensor(3.0016)</td>\n",
       "      <td>tensor(2.0287)</td>\n",
       "      <td>tensor(1.5258)</td>\n",
       "      <td>[[tensor(1.0114), tensor(0.), tensor(0.)], [te...</td>\n",
       "      <td>100_033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>630 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    lambda_clamps_X lambda_clamps_Y mean_stress_x_mpa mean_stress_y_mpa  \\\n",
       "0    tensor(1.0571)  tensor(1.0571)    tensor(0.0023)    tensor(0.0262)   \n",
       "1    tensor(1.0629)  tensor(1.0629)    tensor(0.0027)    tensor(0.0330)   \n",
       "2    tensor(1.0686)  tensor(1.0686)    tensor(0.0032)    tensor(0.0397)   \n",
       "3    tensor(1.0743)  tensor(1.0743)    tensor(0.0038)    tensor(0.0480)   \n",
       "4    tensor(1.0800)  tensor(1.0800)    tensor(0.0046)    tensor(0.0572)   \n",
       "..              ...             ...               ...               ...   \n",
       "625  tensor(1.0286)  tensor(1.0071)    tensor(0.0008)    tensor(0.0205)   \n",
       "626  tensor(1.0229)  tensor(1.0057)   tensor(-0.0002)    tensor(0.0080)   \n",
       "627  tensor(1.0171)  tensor(1.0043)   tensor(-0.0014)   tensor(-0.0009)   \n",
       "628  tensor(1.0114)  tensor(1.0029)   tensor(-0.0056)   tensor(-0.0134)   \n",
       "629  tensor(1.0114)  tensor(1.0029)   tensor(-0.0056)   tensor(-0.0134)   \n",
       "\n",
       "                 I1              I2              I4              I5  \\\n",
       "0    tensor(3.0358)  tensor(3.0385)  tensor(2.1461)  tensor(1.6318)   \n",
       "1    tensor(3.0429)  tensor(3.0466)  tensor(2.1611)  tensor(1.6454)   \n",
       "2    tensor(3.0507)  tensor(3.0554)  tensor(2.1761)  tensor(1.6590)   \n",
       "3    tensor(3.0590)  tensor(3.0649)  tensor(2.1912)  tensor(1.6727)   \n",
       "4    tensor(3.0678)  tensor(3.0752)  tensor(2.2064)  tensor(1.6864)   \n",
       "..              ...             ...             ...             ...   \n",
       "625  tensor(3.0094)  tensor(3.0097)  tensor(2.0722)  tensor(1.5651)   \n",
       "626  tensor(3.0060)  tensor(3.0062)  tensor(2.0577)  tensor(1.5520)   \n",
       "627  tensor(3.0034)  tensor(3.0035)  tensor(2.0432)  tensor(1.5389)   \n",
       "628  tensor(3.0015)  tensor(3.0016)  tensor(2.0287)  tensor(1.5258)   \n",
       "629  tensor(3.0015)  tensor(3.0016)  tensor(2.0287)  tensor(1.5258)   \n",
       "\n",
       "                                                     F experiment_type  \n",
       "0    [[tensor(1.0571), tensor(0.), tensor(0.)], [te...         100_100  \n",
       "1    [[tensor(1.0629), tensor(0.), tensor(0.)], [te...         100_100  \n",
       "2    [[tensor(1.0686), tensor(0.), tensor(0.)], [te...         100_100  \n",
       "3    [[tensor(1.0743), tensor(0.), tensor(0.)], [te...         100_100  \n",
       "4    [[tensor(1.0800), tensor(0.), tensor(0.)], [te...         100_100  \n",
       "..                                                 ...             ...  \n",
       "625  [[tensor(1.0286), tensor(0.), tensor(0.)], [te...         100_033  \n",
       "626  [[tensor(1.0229), tensor(0.), tensor(0.)], [te...         100_033  \n",
       "627  [[tensor(1.0171), tensor(0.), tensor(0.)], [te...         100_033  \n",
       "628  [[tensor(1.0114), tensor(0.), tensor(0.)], [te...         100_033  \n",
       "629  [[tensor(1.0114), tensor(0.), tensor(0.)], [te...         100_033  \n",
       "\n",
       "[630 rows x 10 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_loader, test_data_loader = init_loaders(None)\n",
    "train_data_loader.dataset.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f94f3fd-50d4-46b8-8655-0d18a3c4ec18",
   "metadata": {},
   "source": [
    "# Обучение модели"
   ]
  },
  {
   "cell_type": "raw",
   "id": "03819dd7-5371-43ff-b392-45fcfd9c32c6",
   "metadata": {},
   "source": [
    "experiments=[[\"Shear\", \"Tensile\", \"Comression\"],[\"Tensile\", \"Comression\"], [\"Tensile\", \"Shear\"], [\"Shear\", \"Comression\"], \"Shear\", \"Tensile\", \"Comression\"]\n",
    "for experiment in experiments:\n",
    "    print(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d4e427b-6f31-4571-9577-e1278581b550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Переименуем столбцы для удобства\n",
    "# data.columns = ['strain', 'measured_force', 'I1', 'I2', 'F', 'experiment_type', 'predicted_force']\n",
    "\n",
    "# Удалим ненужные столбцы\n",
    "# data = data[['strain', 'measured_force', 'experiment_type', 'predicted_force']]\n",
    "def plot_results(data:pd.DataFrame, plot_name=\"\"):\n",
    "    # Преобразуем столбец с предсказанной силой в числовой формат\n",
    "    # data['P_model_' + plot_name] = data['P_model_' + plot_name].apply(lambda x: float(str(x).strip('[]')))\n",
    "    data['P_model' + plot_name] = data['P_model' + plot_name].apply(lambda x: float(str(x).strip('[]')))\n",
    "    \n",
    "    # Создадим графики для каждого типа эксперимента\n",
    "    experiment_types = data['experiment_type'].unique()\n",
    "    def plot_with_r2(data, experiment_types):\n",
    "        r2_scores = []\n",
    "        fig, axes = plt.subplots(1, len(experiment_types), figsize=(15, 6), sharey=False)\n",
    "        \n",
    "        for ax, experiment in zip(axes, experiment_types):\n",
    "            subset = data[data['experiment_type'] == experiment]\n",
    "            r2 = r2_score(subset['P_experimental'], subset['P_model' + plot_name])\n",
    "            # r2 = r2_score(subset['P_experimental'], subset['P_model_' + plot_name])\n",
    "            \n",
    "            sns.scatterplot(data=subset, x='lambda', y='P_experimental', label='P_experimental', ax=ax)\n",
    "            # sns.lineplot(data=subset, x='lambda', y='P_model_' + plot_name, label='P_model', color='orange', ax=ax)\n",
    "            sns.lineplot(data=subset, x='lambda', y='P_model' + plot_name, label='P_model', color='orange', ax=ax)\n",
    "            ax.set_title(f'Experiment Type: {experiment}\\nR² = {r2:.2f}')\n",
    "            ax.set_xlabel('Strain')\n",
    "            ax.set_ylabel('Force (kPa)')\n",
    "            r2_scores.append(r2)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(plot_name)\n",
    "        plt.show()\n",
    "        \n",
    "        return r2_scores\n",
    "    # Вызовем функцию для построения графиков с r2\n",
    "    plot_with_r2(data, experiment_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28327c59-a6ec-4082-ad51-8ce7c899398c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "Directory pretrained_models\\GoreTex_StrainEnergyCANN_Ani already exists\n",
      "LOSS train 2.2761738916223364 valid 2.2761738916223364\n",
      "------------------------------------------------------------------\n",
      "Epoch [1/5000], Loss: 2.27617389, Test metric: 2.27617389\n",
      "LOSS train 1.6182422980172781 valid 1.6182422980172781\n",
      "------------------------------------------------------------------\n",
      "Epoch [2/5000], Loss: 1.61824230, Test metric: 1.61824230\n",
      "LOSS train 1.9656899992597154 valid 1.9656899992597154\n",
      "LOSS train 3.015267745894472 valid 3.015267745894472\n",
      "LOSS train 4.875664280898987 valid 4.875664280898987\n",
      "LOSS train 7.399904443347265 valid 7.399904443347265\n",
      "LOSS train 10.737167359155322 valid 10.737167359155322\n",
      "LOSS train 14.897846016051277 valid 14.897846016051277\n",
      "LOSS train 20.03174104236421 valid 20.03174104236421\n",
      "LOSS train 25.413053539821078 valid 25.413053539821078\n",
      "LOSS train 31.447461088876874 valid 31.447461088876874\n",
      "LOSS train 38.61359638335213 valid 38.61359638335213\n",
      "LOSS train 46.72030891842312 valid 46.72030891842312\n",
      "LOSS train 56.130695070539204 valid 56.130695070539204\n",
      "LOSS train 67.04412466382223 valid 67.04412466382223\n",
      "LOSS train 79.09146464514355 valid 79.09146464514355\n",
      "LOSS train 92.68398103259858 valid 92.68398103259858\n",
      "LOSS train 108.04478783985925 valid 108.04478783985925\n",
      "LOSS train 124.88515640743195 valid 124.88515640743195\n",
      "LOSS train 143.523295133076 valid 143.523295133076\n",
      "LOSS train 164.33288999285017 valid 164.33288999285017\n",
      "LOSS train 186.92626876831054 valid 186.92626876831054\n",
      "LOSS train 211.33960520426433 valid 211.33960520426433\n",
      "LOSS train 238.44281526595827 valid 238.44281526595827\n",
      "LOSS train 267.70503770131916 valid 267.70503770131916\n",
      "LOSS train 299.8746066623264 valid 299.8746066623264\n",
      "LOSS train 334.5457843841068 valid 334.5457843841068\n",
      "LOSS train 371.2465908232189 valid 371.2465908232189\n",
      "LOSS train 411.74560692196803 valid 411.74560692196803\n",
      "LOSS train 455.3183070591518 valid 455.3183070591518\n",
      "LOSS train 501.7682313464937 valid 501.7682313464937\n",
      "LOSS train 552.0329880971757 valid 552.0329880971757\n",
      "LOSS train 605.2566511366102 valid 605.2566511366102\n",
      "LOSS train 662.0440238347129 valid 662.0440238347129\n",
      "LOSS train 723.5809933132596 valid 723.5809933132596\n",
      "LOSS train 787.5773308648004 valid 787.5773308648004\n",
      "LOSS train 857.5936635819693 valid 857.5936635819693\n",
      "LOSS train 931.3849853515625 valid 931.3849853515625\n",
      "LOSS train 1008.3174128456722 valid 1008.3174128456722\n",
      "LOSS train 1091.6618098183283 valid 1091.6618098183283\n",
      "LOSS train 1179.743510703435 valid 1179.743510703435\n",
      "LOSS train 1272.5776000976562 valid 1272.5776000976562\n",
      "LOSS train 1371.3929858010913 valid 1371.3929858010913\n",
      "LOSS train 1474.6636381603423 valid 1474.6636381603423\n",
      "LOSS train 1584.6305671812995 valid 1584.6305671812995\n",
      "LOSS train 1699.022371419271 valid 1699.022371419271\n",
      "LOSS train 1821.6949092804439 valid 1821.6949092804439\n",
      "LOSS train 1948.4462065197172 valid 1948.4462065197172\n",
      "LOSS train 2083.8540728856647 valid 2083.8540728856647\n",
      "LOSS train 2224.229156203497 valid 2224.229156203497\n",
      "LOSS train 2373.6834968687995 valid 2373.6834968687995\n",
      "LOSS train 2527.8017120845734 valid 2527.8017120845734\n",
      "LOSS train 2691.019761827257 valid 2691.019761827257\n",
      "LOSS train 2861.9174647739956 valid 2861.9174647739956\n",
      "LOSS train 3042.311099097842 valid 3042.311099097842\n",
      "LOSS train 3226.8324625651044 valid 3226.8324625651044\n",
      "LOSS train 3423.6958499968996 valid 3423.6958499968996\n",
      "LOSS train 3626.7708492218503 valid 3626.7708492218503\n",
      "LOSS train 3838.795666310144 valid 3838.795666310144\n",
      "LOSS train 4062.7448432074652 valid 4062.7448432074652\n",
      "LOSS train 4292.846175905258 valid 4292.846175905258\n",
      "LOSS train 4536.616265966022 valid 4536.616265966022\n",
      "LOSS train 4788.703658234127 valid 4788.703658234127\n",
      "LOSS train 5048.439575970362 valid 5048.439575970362\n",
      "LOSS train 5322.030481925844 valid 5322.030481925844\n",
      "LOSS train 5606.816778273809 valid 5606.816778273809\n",
      "LOSS train 5902.887291511657 valid 5902.887291511657\n",
      "LOSS train 6206.392154947916 valid 6206.392154947916\n",
      "LOSS train 6525.2834255642365 valid 6525.2834255642365\n",
      "LOSS train 6855.899053664434 valid 6855.899053664434\n",
      "LOSS train 7197.290978422619 valid 7197.290978422619\n",
      "LOSS train 7551.194133649554 valid 7551.194133649554\n",
      "LOSS train 7923.94171859499 valid 7923.94171859499\n",
      "LOSS train 8301.155587332589 valid 8301.155587332589\n",
      "LOSS train 8698.271644810267 valid 8698.271644810267\n",
      "LOSS train 9106.936574590774 valid 9106.936574590774\n",
      "LOSS train 9529.008737134176 valid 9529.008737134176\n",
      "LOSS train 9970.81079876612 valid 9970.81079876612\n",
      "LOSS train 10422.659598214286 valid 10422.659598214286\n",
      "LOSS train 10894.669349888392 valid 10894.669349888392\n",
      "LOSS train 11378.467314608135 valid 11378.467314608135\n",
      "LOSS train 11874.575748697916 valid 11874.575748697916\n",
      "LOSS train 12396.375396825397 valid 12396.375396825397\n",
      "LOSS train 12929.566097780258 valid 12929.566097780258\n",
      "LOSS train 13477.683472842262 valid 13477.683472842262\n",
      "LOSS train 14042.94244016617 valid 14042.94244016617\n",
      "LOSS train 14635.923417348711 valid 14635.923417348711\n",
      "LOSS train 15235.062555803572 valid 15235.062555803572\n",
      "LOSS train 15862.847098214286 valid 15862.847098214286\n",
      "LOSS train 16500.588506014385 valid 16500.588506014385\n",
      "LOSS train 17161.39752139137 valid 17161.39752139137\n",
      "LOSS train 17844.417190600198 valid 17844.417190600198\n",
      "LOSS train 18544.653097098213 valid 18544.653097098213\n",
      "LOSS train 19271.642254154267 valid 19271.642254154267\n",
      "LOSS train 20007.078720238096 valid 20007.078720238096\n",
      "LOSS train 20774.297065662202 valid 20774.297065662202\n",
      "LOSS train 21557.288507564484 valid 21557.288507564484\n",
      "LOSS train 22372.907263764882 valid 22372.907263764882\n",
      "LOSS train 23193.04920014881 valid 23193.04920014881\n",
      "LOSS train 24044.992007688492 valid 24044.992007688492\n",
      "LOSS train 24932.367646329367 valid 24932.367646329367\n",
      "Epoch [101/5000], Loss: 24932.36764633, Test metric: 24932.36764633\n",
      "LOSS train 25828.72439236111 valid 25828.72439236111\n",
      "LOSS train 26751.534461805557 valid 26751.534461805557\n",
      "LOSS train 27709.967060391864 valid 27709.967060391864\n",
      "LOSS train 28678.5703156002 valid 28678.5703156002\n",
      "LOSS train 29685.414772445438 valid 29685.414772445438\n",
      "LOSS train 30697.71259920635 valid 30697.71259920635\n",
      "LOSS train 31759.532412574405 valid 31759.532412574405\n",
      "LOSS train 32825.212862723216 valid 32825.212862723216\n",
      "LOSS train 33950.08607080853 valid 33950.08607080853\n",
      "LOSS train 35087.12329799107 valid 35087.12329799107\n",
      "LOSS train 36246.5558469742 valid 36246.5558469742\n",
      "LOSS train 37432.85248945933 valid 37432.85248945933\n",
      "LOSS train 38657.583993675595 valid 38657.583993675595\n",
      "LOSS train 39898.94820498512 valid 39898.94820498512\n",
      "LOSS train 41187.7939422123 valid 41187.7939422123\n",
      "LOSS train 42507.088994295635 valid 42507.088994295635\n",
      "LOSS train 43844.497749255956 valid 43844.497749255956\n",
      "LOSS train 45227.31881820437 valid 45227.31881820437\n",
      "LOSS train 46619.26223958333 valid 46619.26223958333\n",
      "LOSS train 48062.00894717262 valid 48062.00894717262\n",
      "LOSS train 49539.73704737103 valid 49539.73704737103\n",
      "LOSS train 51046.29283234127 valid 51046.29283234127\n",
      "LOSS train 52569.59605654762 valid 52569.59605654762\n",
      "LOSS train 54166.60166170635 valid 54166.60166170635\n",
      "LOSS train 55781.4763578869 valid 55781.4763578869\n",
      "LOSS train 57394.908444940476 valid 57394.908444940476\n",
      "LOSS train 59098.37654389881 valid 59098.37654389881\n",
      "LOSS train 60820.239167906744 valid 60820.239167906744\n",
      "LOSS train 62574.302021329364 valid 62574.302021329364\n",
      "LOSS train 64370.58138640873 valid 64370.58138640873\n",
      "LOSS train 66203.42548363096 valid 66203.42548363096\n",
      "LOSS train 68079.20283358135 valid 68079.20283358135\n",
      "LOSS train 69979.3695064484 valid 69979.3695064484\n",
      "LOSS train 71941.53829985119 valid 71941.53829985119\n",
      "LOSS train 73940.9220672123 valid 73940.9220672123\n",
      "LOSS train 75968.0140687004 valid 75968.0140687004\n",
      "LOSS train 78019.1800905258 valid 78019.1800905258\n",
      "LOSS train 80167.89446924604 valid 80167.89446924604\n",
      "LOSS train 82311.509765625 valid 82311.509765625\n",
      "LOSS train 84507.88058035714 valid 84507.88058035714\n",
      "LOSS train 86761.2663938492 valid 86761.2663938492\n",
      "LOSS train 89064.27217261905 valid 89064.27217261905\n",
      "LOSS train 91397.99370039682 valid 91397.99370039682\n",
      "LOSS train 93771.11320684524 valid 93771.11320684524\n",
      "LOSS train 96218.02875744048 valid 96218.02875744048\n",
      "LOSS train 98687.07383432539 valid 98687.07383432539\n",
      "LOSS train 101221.89176587302 valid 101221.89176587302\n",
      "LOSS train 103769.7165922619 valid 103769.7165922619\n",
      "LOSS train 106376.42101934523 valid 106376.42101934523\n",
      "LOSS train 109071.30979662699 valid 109071.30979662699\n",
      "LOSS train 111805.38937251984 valid 111805.38937251984\n",
      "LOSS train 114564.78655753969 valid 114564.78655753969\n",
      "LOSS train 117387.55719246031 valid 117387.55719246031\n",
      "LOSS train 120235.13229166667 valid 120235.13229166667\n",
      "LOSS train 123154.8334077381 valid 123154.8334077381\n",
      "LOSS train 126159.93439980158 valid 126159.93439980158\n",
      "LOSS train 129206.33232886904 valid 129206.33232886904\n",
      "LOSS train 132273.41254960318 valid 132273.41254960318\n",
      "LOSS train 135419.3920138889 valid 135419.3920138889\n",
      "LOSS train 138605.43716517856 valid 138605.43716517856\n",
      "LOSS train 141889.11009424602 valid 141889.11009424602\n",
      "LOSS train 145161.90027281747 valid 145161.90027281747\n",
      "LOSS train 148558.31178075398 valid 148558.31178075398\n",
      "LOSS train 151965.20487351192 valid 151965.20487351192\n",
      "LOSS train 155495.59371279762 valid 155495.59371279762\n",
      "LOSS train 159032.69224950398 valid 159032.69224950398\n",
      "LOSS train 162624.34779265872 valid 162624.34779265872\n",
      "LOSS train 166281.25771329366 valid 166281.25771329366\n",
      "LOSS train 170001.42671130953 valid 170001.42671130953\n",
      "LOSS train 173814.29384920635 valid 173814.29384920635\n",
      "LOSS train 177653.4822420635 valid 177653.4822420635\n",
      "LOSS train 181554.91331845237 valid 181554.91331845237\n"
     ]
    }
   ],
   "source": [
    "# experiments=[[\"Tensile\", \"Comression\"], [\"Tensile\", \"Shear\"], [\"Shear\", \"Comression\"], \"Shear\", \"Tensile\", \"Compression\"]\n",
    "# experiments = [\"Tensile\", \"Comression\", \"Shear\"]\n",
    "# models = [StrainEnergyCANN_C, StrainEnergyCANN_polinomial3]\n",
    "models = [StrainEnergyCANN_Ani]\n",
    "path = r\"C:\\Users\\User\\PycharmProjects\\data-driven-constitutive-modelling\\src\\CANN_torch\\pretrained_models\"\n",
    "for model in models:\n",
    "\n",
    "\n",
    "    # for idx, experiment in enumerate(experiments):\n",
    "        train_data_loader, test_data_loader = init_loaders(None)\n",
    "        name = \"GoreTex_\" + str(model.__name__)\n",
    "        print(\"----------------------------------------------------------------------\")\n",
    "        # print(experiment)\n",
    "        test_train = Trainer(\n",
    "            plot_valid=False,\n",
    "            epochs=5000,\n",
    "            experiment_name=name,\n",
    "            l2_reg_coeff=None,\n",
    "            learning_rate=0.0001,\n",
    "            checkpoint=None,\n",
    "            model=model\n",
    "            # dtype = torch.float64\n",
    "        )\n",
    "        \n",
    "        trained_model = test_train.train(train_data_loader, None, weighting_data=False)\n",
    "    \n",
    "        trained_model.eval()\n",
    "        vpredictions = []\n",
    "        vtargets = []\n",
    "        for data in test_data_loader:\n",
    "            features, target = data\n",
    "            vpredictions.append(zip(trained_model(features).detach().numpy()))\n",
    "        print(trained_model.get_potential())\n",
    "        \n",
    "        combined_data[\"P_model_\" + name] = vpredictions\n",
    "        plot_results(combined_data, name)\n",
    "        combined_data.to_csv(os.path.join(os.path.join(path, str(name)), \"data.csv\"))\n",
    "        combined_data.pop(\"P_model_\" + name)\n",
    "# trained_model = StrainEnergyCANN_C()\n",
    "\n",
    "\n",
    "# print(\"R2:\", r2_score_own(vtargets, vpredictions))\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(vpredictions, label='P_pred', color='red')\n",
    "# plt.plot(vtargets, label='P_true', color='black')\n",
    "# plt.xlabel('lambda/gamma')\n",
    "# plt.ylabel('P')\n",
    "# plt.title('Predictions vs. Targets')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba20f7e-2aec-4348-bbd0-2866fc1bd4cd",
   "metadata": {},
   "source": [
    "$psi =   0.000000 * (I1 - 3) \\\\               + 0.026245 * (e^{  0.000000 * (I1 - 3)} - 1)\\\\               - 0.025429 * ln(1 - 0.052720 * (I1 - 3)) \\\\               + 0.000000 * (I1 - 3) ^ 2 \\\\               + 0.085033 * (e^{  0.000000 * (I1 - 3) ^ 2} - 1)\\\\               - 0.077004 * ln(1 - 0.046803 * (I1 - 3) ^ 2) \\\\                               + 0.006244 * (I2 - 3) \\\\               + 0.046553 * (e^{  0.060594 * (I2 - 3))} - 1)\\\\               - 0.123550* ln(1 - 0.126146 *  (I2 - 3)) \\\\               + 0.000000 * (I2 - 3) ^ 2 \\\\               + 0.132380 * (e^{  0.051048 *(I2 - 3) ^ 2)} - 1)\\\\               - 0.018332* ln(1 - 0.074555 * (I2 - 3) ^ 2)\\\\$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf389cac-f1aa-400a-800f-2e1d069ceccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = r\"C:\\Users\\User\\PycharmProjects\\data-driven-constitutive-modelling_old\\src\\CANN_torch\\pretrained_models\\PDMS_full\\20240522_1306_2681.pth\"\n",
    "trained_model = StrainEnergyCANN_polinomial3()\n",
    "trained_model.load_state_dict(torch.load(best_model_path))\n",
    "trained_model.eval()\n",
    "vpredictions = []\n",
    "vtargets = []\n",
    "for data in test_data_loader:\n",
    "    features, target = data\n",
    "    vpredictions.append(trained_model(features).detach().numpy())\n",
    "print(trained_model.get_potential())\n",
    "combined_data[\"P_model\"] = vpredictions\n",
    "\n",
    "plot_results(combined_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319160bd-67b8-4313-a38f-6439d3dd3c4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de458688-1c6a-4a83-82d6-931e84a87398",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
